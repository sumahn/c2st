{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/miniconda3/envs/mmdenv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import matplotlib.pyplot as plt\n",
    "from jax.random import multivariate_normal\n",
    "# from sampler_mixture import sampler_mixture \n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "# from utils_debias import MMDVar as MMD_var_u\n",
    "from utils import MMDVar, compute_mmd_sq, compute_K_matrices, h1_mean_var_gram, MMDu_var, Vstat_MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (6,) and (9,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/oldrain123/C2ST/experiments2.ipynb 셀 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B165.132.79.140/home/oldrain123/C2ST/experiments2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B165.132.79.140/home/oldrain123/C2ST/experiments2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m KXY \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39marray([[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B165.132.79.140/home/oldrain123/C2ST/experiments2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m                  [\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B165.132.79.140/home/oldrain123/C2ST/experiments2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m                  [\u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m9\u001b[39m]])  \u001b[39m# Replace this with your actual KXY matrix\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B165.132.79.140/home/oldrain123/C2ST/experiments2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m result \u001b[39m=\u001b[39m compute_reduced_moment(KXY)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B165.132.79.140/home/oldrain123/C2ST/experiments2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe result of the reduced moment is:\u001b[39m\u001b[39m\"\u001b[39m, result)\n",
      "\u001b[1;32m/home/oldrain123/C2ST/experiments2.ipynb 셀 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B165.132.79.140/home/oldrain123/C2ST/experiments2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m one_n \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mones((n \u001b[39m*\u001b[39m (n\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B165.132.79.140/home/oldrain123/C2ST/experiments2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Calculate the reduced moment\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B165.132.79.140/home/oldrain123/C2ST/experiments2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m reduced_moment \u001b[39m=\u001b[39m one_m \u001b[39m@\u001b[39;49m KXY_KXY_kron \u001b[39m@\u001b[39m one_n\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B165.132.79.140/home/oldrain123/C2ST/experiments2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mreturn\u001b[39;00m reduced_moment\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdenv/lib/python3.9/site-packages/jax/_src/numpy/array_methods.py:256\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    254\u001b[0m args \u001b[39m=\u001b[39m (other, \u001b[39mself\u001b[39m) \u001b[39mif\u001b[39;00m swap \u001b[39melse\u001b[39;00m (\u001b[39mself\u001b[39m, other)\n\u001b[1;32m    255\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 256\u001b[0m   \u001b[39mreturn\u001b[39;00m binary_op(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    257\u001b[0m \u001b[39m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(other) \u001b[39min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdenv/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:3192\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(a, b, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   3190\u001b[0m a \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39msqueeze(a, \u001b[39mtuple\u001b[39m(a_squeeze))\n\u001b[1;32m   3191\u001b[0m b \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39msqueeze(b, \u001b[39mtuple\u001b[39m(b_squeeze))\n\u001b[0;32m-> 3192\u001b[0m out \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39;49mdot_general(\n\u001b[1;32m   3193\u001b[0m   a, b, (((ndim(a) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,), (ndim(b) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m b_is_mat,)), (a_batch, b_batch)),\n\u001b[1;32m   3194\u001b[0m   precision\u001b[39m=\u001b[39;49mprecision, preferred_element_type\u001b[39m=\u001b[39;49mpreferred_element_type)\n\u001b[1;32m   3195\u001b[0m result \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39mtranspose(out, perm)\n\u001b[1;32m   3196\u001b[0m \u001b[39mreturn\u001b[39;00m lax_internal\u001b[39m.\u001b[39m_convert_element_type(result, preferred_element_type, output_weak_type)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdenv/lib/python3.9/site-packages/jax/_src/lax/lax.py:2558\u001b[0m, in \u001b[0;36m_dot_general_shape_rule\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   2555\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m core\u001b[39m.\u001b[39mdefinitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[1;32m   2556\u001b[0m   msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2557\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mshape, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2558\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[1;32m   2560\u001b[0m \u001b[39mreturn\u001b[39;00m _dot_general_shape_computation(lhs\u001b[39m.\u001b[39mshape, rhs\u001b[39m.\u001b[39mshape, dimension_numbers)\n",
      "\u001b[0;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got (6,) and (9,)."
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def compute_reduced_moment(KXY):\n",
    "    m, n = KXY.shape\n",
    "    \n",
    "    # Create KXY' by removing the last column from KXY\n",
    "    KXY_prime = KXY[:, :-1]\n",
    "\n",
    "    # Compute the Kronecker product KXY' ⊗ KXY'\n",
    "    KXY_KXY_kron = jnp.kron(KXY_prime, KXY_prime)\n",
    "\n",
    "    # Create vectors of ones with shapes compatible with the Kronecker product dimensions\n",
    "    one_m = jnp.ones((m * (m-1),))\n",
    "    one_n = jnp.ones((n * (n-1),))\n",
    "\n",
    "    # Calculate the reduced moment\n",
    "    reduced_moment = one_m @ KXY_KXY_kron @ one_n\n",
    "    \n",
    "    return reduced_moment\n",
    "\n",
    "# Example usage\n",
    "KXY = jnp.array([[1, 2, 3],\n",
    "                 [4, 5, 6],\n",
    "                 [7, 8, 9]])  # Replace this with your actual KXY matrix\n",
    "\n",
    "result = compute_reduced_moment(KXY)\n",
    "print(\"The result of the reduced moment is:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate samples from multivariate normal distribution\n",
    "def sample_mvn(key, mean, cov, num_samples):\n",
    "    return multivariate_normal(mean=mean, cov=cov, shape=num_samples, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decreasing signal as n grows\n",
    "key = random.PRNGKey(42)\n",
    "\n",
    "\n",
    "# Number of times to estimate MMD\n",
    "iteraion = 1000\n",
    "# Array to store MMD values\n",
    "mmd_samples = jnp.zeros(iteraion)\n",
    "\n",
    "full_v = jnp.zeros(iteraion)\n",
    "com_2_v = jnp.zeros(iteraion)\n",
    "\n",
    "# u for debias\n",
    "full_u = jnp.zeros(iteraion)\n",
    "com_2_u = jnp.zeros(iteraion)\n",
    "Liu = jnp.zeros(iteraion)\n",
    "\n",
    "\n",
    "# Sample sizes and variance data\n",
    "full_v_variances = []\n",
    "complete_v_variances = []\n",
    "full_u_variances = []\n",
    "complete_u_variances = []\n",
    "liu_variances = []\n",
    "\n",
    "\n",
    "sigma0 = 1.0\n",
    "\n",
    "num_samples = [32,64,100,200,300,400,500,600,700,800,900,1000,2000,3000,4000,5000]\n",
    "\n",
    "for sample_size in num_samples :\n",
    "    \n",
    "    print(\"number of samples : \",sample_size)\n",
    "    shift = 10 / jnp.sqrt(sample_size)\n",
    "    mean1 = jnp.zeros(5)\n",
    "    mean2 = mean1 + shift\n",
    "    \n",
    "    cov = jnp.eye(5)\n",
    "    \n",
    "    # Monte Carlo simulation to estimate MMD values\n",
    "    for i in range(iteraion):\n",
    "        key, subkey1, subkey2 = random.split(key, 3)\n",
    "        X = sample_mvn(subkey1, mean1, cov, (sample_size,))\n",
    "        Y = sample_mvn(subkey2, mean2, cov, (sample_size,))\n",
    "\n",
    "        Kxx, Kyy, Kxy = compute_K_matrices(X, Y, sigma0)\n",
    "        m = X.shape[0]\n",
    "        n = Y.shape[0]\n",
    "        mmd_value = compute_mmd_sq(Kxx, Kyy, Kxy, m, n)\n",
    "        \n",
    "        mmd_samples = mmd_samples.at[i].set(mmd_value)\n",
    "        full_v = full_v.at[i].set(MMDVar(X, Y, sigma0, copmlete=True, bias=False))\n",
    "        com_2_v = com_2_v.at[i].set(MMDVar(X, Y, sigma0, complete=False))\n",
    "        Liu = Liu.at[i].set(h1_mean_var_gram(Kxx, Kyy, Kxy, is_var_computed=True, use_1sample_U=True)[1])\n",
    "    \n",
    "    # Compute estimated variance of MMD\n",
    "    mmd_variance = jnp.var(mmd_samples, ddof=1)\n",
    "    full_v_variances.append(jnp.abs(jnp.abs(jnp.median(full_v))-mmd_variance)/mmd_variance)\n",
    "    complete_v_variances.append(jnp.abs(jnp.abs(jnp.median(com_2_v))-mmd_variance)/mmd_variance)\n",
    "    liu_variances.append(jnp.abs(jnp.median(Liu)-mmd_variance)/mmd_variance)\n",
    "    \n",
    "    print(\"The average of MMDu\",jnp.average(mmd_samples))\n",
    "    print(\"True Variance of MMD:\", mmd_variance)\n",
    "\n",
    "    # Compare the results\n",
    "    print()\n",
    "    print(\"How accurate estimators estimate the variance : estimator/true\")\n",
    "    print(f\"Biased Full Variance Estimate (Ours 8): {jnp.abs(jnp.abs(jnp.median(full_v))-mmd_variance)/mmd_variance}\")\n",
    "    print(f\"Biased Complete Variance Estimate (Ours 2): {jnp.abs(jnp.abs(jnp.median(com_2_v))-mmd_variance)/mmd_variance}\")\n",
    "    print(f\"Incomplete Variance Estimate (Liu et al. 2): {jnp.abs(jnp.median(Liu)-mmd_variance)/mmd_variance}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Mean Difference (Equal Sample Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_mmd(mean1, mean2, cov1, cov2, ratio, num_samples, sigma0):\n",
    "    mmd_samples = jnp.zeros(100)\n",
    "    full_vars, complete_vars, incomplete_vars = [], [], []\n",
    "\n",
    "    key = random.PRNGKey(42) # Set random seed\n",
    "    for i in range(100):\n",
    "        key, subkey1, subkey2 = random.split(key, 3)\n",
    "        X = multivariate_normal(mean=mean1, cov=cov1, shape=(num_samples * ratio,), key=subkey1)\n",
    "        Y = multivariate_normal(mean=mean2, cov=cov2, shape=(num_samples * ratio,), key=subkey2)\n",
    "\n",
    "        Kxx, Kyy, Kxy = compute_K_matrices(X, Y, sigma0)\n",
    "        mmd_value = compute_mmd_sq(Kxx, Kyy, Kxy, len(X), len(Y))\n",
    "        mmd_samples = mmd_samples.at[i].set(mmd_value)\n",
    "\n",
    "        full_vars.append(MMDVar(X, Y, sigma0))\n",
    "        complete_vars.append(MMDVar(X, Y, sigma0, complete=False))\n",
    "        incomplete_vars.append(h1_mean_var_gram(Kxx, Kyy, Kxy, is_var_computed=True, use_1sample_U=True)[1])\n",
    "\n",
    "    return mmd_samples, full_vars, complete_vars, incomplete_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_json(results, filename=\"mmd_results.json\"):\n",
    "    with open(filename, 'w') as f:\n",
    "        # Convert JAX arrays to native Python lists for serialization\n",
    "        json_results = jax.tree_map(lambda x: x.tolist() if isinstance(x, jnp.ndarray) else x, results)\n",
    "        json.dump(json_results, f, indent=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma0 = 1.0\n",
    "num_samples = 100\n",
    "ratios = [1, 3, 5, 7, 10]\n",
    "mean_differences = jnp.linspace(0.0001, 0.1, num=5)\n",
    "\n",
    "cov1 = jnp.eye(5)\n",
    "cov2 = jnp.eye(5)\n",
    "\n",
    "results = {}\n",
    "print(\"Running...\")\n",
    "for mean_diff in tqdm(mean_differences):\n",
    "    mean1 = jnp.zeros(5)\n",
    "    mean2 = jnp.array([mean_diff] * 5)\n",
    "    \n",
    "    for ratio in tqdm(ratios):\n",
    "        mmd_samples, full_vars, complete_vars, incomplete_vars = simulate_mmd(mean1, mean2, cov1, cov2, ratio, num_samples, sigma0)\n",
    "\n",
    "        true_variance = jnp.var(mmd_samples, ddof=1)\n",
    "        \n",
    "        results_key = (float(mean_diff.item()), ratio)\n",
    "        results[results_key] = {\n",
    "            'true_variance': true_variance,\n",
    "            'full_variance_estimate': jnp.mean(jnp.array(full_vars)),\n",
    "            'complete_variance_estimate': jnp.mean(jnp.array(complete_vars)),\n",
    "            'incomplete_variance_estimate': jnp.mean(jnp.array(incomplete_vars))\n",
    "        }\n",
    "        print(results[results_key])\n",
    "\n",
    "for (mean_diff, ratio), vals in results.items():\n",
    "    print(f\"Mean Difference: {mean_diff}, Ratio: {ratio}\")\n",
    "    print(f\"MMDu: {vals['true_variance']}\")\n",
    "    print(f\"True Variance of MMD: {vals['true_variance']}\")\n",
    "    print(f\"Full Variance Estimate (Ours 8): {vals['full_variance_estimate']}\")\n",
    "    print(f\"Complete Variance Estimate (Ours 2): {vals['complete_variance_estimate']}\")\n",
    "    print(f\"Incomplete Variance Estimate (Liu et al. 2): {vals['incomplete_variance_estimate']}\")\n",
    "    print(\"-------\")\n",
    "\n",
    "# save_results_to_json(results, \"mmd_results.json\")\n",
    "# print(\"Results saved to mmd_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate means and variances for each estimation method\n",
    "full_var_means = [jnp.mean(full_var_estimates[ratio]) for ratio in ratios]\n",
    "full_var_std = [jnp.std(full_var_estimates[ratio]) for ratio in ratios]\n",
    "\n",
    "complete_var_means = [jnp.mean(complete_var_estimates[ratio]) for ratio in ratios]\n",
    "complete_var_std = [jnp.std(complete_var_estimates[ratio]) for ratio in ratios]\n",
    "\n",
    "complete_var_h_means = [jnp.mean(complete_var_h_estimates[ratio]) for ratio in ratios]\n",
    "complete_var_h_std = [jnp.std(complete_var_h_estimates[ratio]) for ratio in ratios]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot means and variance bands for each method\n",
    "plt.errorbar(ratios, full_var_means, yerr=full_var_std, fmt='-o', label=\"Full Variance Estimate\")\n",
    "plt.errorbar(ratios, complete_var_means, yerr=complete_var_std, fmt='-o', label=\"Complete Variance Estimate\")\n",
    "plt.errorbar(ratios, complete_var_h_means, yerr=complete_var_h_std, fmt='-o', label=\"Complete Variance Estimate using h\")\n",
    "\n",
    "# If you want to plot the incomplete variance estimate (only for ratio = 1)\n",
    "if incomplete_var_estimates:\n",
    "    plt.scatter([1], [incomplete_var_estimates[0]], color='red', marker='x', label=\"Incomplete Variance Estimate\")\n",
    "\n",
    "plt.title(\"Variance Estimates against Imbalance Ratio\")\n",
    "plt.xlabel(\"Imbalance Ratio\")\n",
    "plt.ylabel(\"Variance Estimate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ratios[2:], true_mmd_variances[2:], '-o', label='True Variance of MMD')\n",
    "plt.plot(ratios[2:], full_var_estimates[2:], '-o', label='Full Variance Estimate (Ours 8)')\n",
    "plt.plot(ratios[2:], complete_var_estimates[2:], '-o', label='Complete Variance Estimate (Ours 2)')\n",
    "plt.plot(ratios[2:], complete_var_h_estimates[2:], '-o', label='Complete Variance Estimate using h (Ours 2)')\n",
    "# plt.plot(ratios, incomplete_var_estimates, '-o', label='Incomplete Variance Estimate (Liu et al. 2)')\n",
    "\n",
    "plt.xlabel('Imbalance Ratio')\n",
    "plt.ylabel('Variance Estimate')\n",
    "plt.title('Variance of MMD by Imbalance Ratios')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equal Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "key = random.PRNGKey(42)\n",
    "\n",
    "# First dataset\n",
    "mean1 = jnp.zeros(5)\n",
    "cov1 = jnp.eye(5)\n",
    "\n",
    "# Second dataset\n",
    "mean2 = jnp.zeros(5)\n",
    "cov2 = jnp.eye(5)\n",
    "cov2 = cov2.at[3, 4].set(0.8)\n",
    "cov2 = cov2.at[4, 3].set(0.8)\n",
    "\n",
    "# Function to generate samples from multivariate normal distribution\n",
    "def sample_mvn(key, mean, cov, num_samples):\n",
    "    return multivariate_normal(mean=mean, cov=cov, shape=num_samples, key=key)\n",
    "\n",
    "# Number of times to estimate MMD\n",
    "num_samples = 1000\n",
    "\n",
    "# Imbalance ratios \n",
    "ratios = [1, 10, 30, 50]\n",
    "\n",
    "eq_true_mmd_variances = []\n",
    "eq_full_var_estimates = []\n",
    "eq_complete_var_estimates = []\n",
    "eq_complete_var_h_estimates = []\n",
    "eq_incomplete_var_estimates = []\n",
    "\n",
    "# Array to store MMD values\n",
    "mmd_samples = jnp.zeros(num_samples)\n",
    "sigma0 = 1\n",
    "\n",
    "# Monte Carlo simulation to estimate MMD values\n",
    "for ratio in ratios:\n",
    "    for i in range(num_samples):\n",
    "        key, subkey1, subkey2 = random.split(key, 3)\n",
    "        X = sample_mvn(subkey1, mean1, cov1, (10 * ratio,))\n",
    "        Y = sample_mvn(subkey2, mean2, cov2, (10 * ratio,))\n",
    "\n",
    "        Kxx, Kyy, Kxy = compute_K_matrices(X, Y, sigma0)\n",
    "        mmd_value = compute_mmd_sq(Kxx, Kyy, Kxy, len(X), len(Y))\n",
    "\n",
    "        mmd_samples = mmd_samples.at[i].set(mmd_value)\n",
    "\n",
    "    # Compute estimated variance of MMD\n",
    "    mmd_variance = jnp.var(mmd_samples, ddof=1)\n",
    "\n",
    "    # Store results in the lists\n",
    "    eq_true_mmd_variances.append(mmd_variance)\n",
    "    eq_full_var_estimates.append(MMDVar(X, Y, sigma0))\n",
    "    eq_complete_var_estimates.append(MMDVar(X, Y, sigma0, complete=False))\n",
    "    eq_complete_var_h_estimates.append(MMDu_var(Kxx, Kyy, Kxy))\n",
    "    eq_incomplete_var_estimates.append(h1_mean_var_gram(Kxx, Kyy, Kxy, is_var_computed=True, use_1sample_U=True)[1])\n",
    "    \n",
    "    print(f\"Sample Size: {10 * ratio, 10 * ratio}\")\n",
    "    print(f\"MMDu: {mmd_value}\")\n",
    "    print(\"True Variance of MMD:\", mmd_variance)\n",
    "\n",
    "    # Compare the results\n",
    "    print(f\"Full Variance Estimate (Ours 8): {MMDVar(X, Y, sigma0)}\")\n",
    "    print(f\"Complete Variance Estimate (Ours 2): {MMDVar(X, Y, sigma0, complete=False)}\")\n",
    "    print(f\"Complete Variance Estimate using h (Ours 2): {MMDu_var(Kxx, Kyy, Kxy)}\")\n",
    "    print(f\"Incomplete Variance Estimate (Liu et al. 2): {h1_mean_var_gram(Kxx, Kyy, Kxy, is_var_computed=True, use_1sample_U=True)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ratios[2:], eq_true_mmd_variances[2:], '-o', label='True Variance of MMD')\n",
    "plt.plot(ratios[2:], eq_full_var_estimates[2:], '-o', label='Full Variance Estimate (Ours 8)')\n",
    "plt.plot(ratios[2:], eq_complete_var_estimates[2:], '-o', label='Complete Variance Estimate (Ours 2)')\n",
    "plt.plot(ratios[2:], eq_complete_var_h_estimates[2:], '-o', label='Complete Variance Estimate using h (Ours 2)')\n",
    "plt.plot(ratios[2:], eq_incomplete_var_estimates[2:], '-o', label='Incomplete Variance Estimate (Liu et al. 2)')\n",
    "\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('Variance Estimate')\n",
    "plt.title('Variance of MMD by Different Sample Size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sigma0 = 1.0\n",
    "num_samples = [1000, 1500, 2000, 2500, 3000]\n",
    "\n",
    "# Arrays to store results\n",
    "true_variances = []\n",
    "method1_variances = []\n",
    "method2_variances = []\n",
    "method3_variances = []\n",
    "method4_variances = []\n",
    "method1_times = []\n",
    "method2_times = []\n",
    "method3_times = []\n",
    "method4_times = []\n",
    "\n",
    "for N in num_samples:\n",
    "    mmd_samples = jnp.zeros(100)\n",
    "    \n",
    "    key, subkey1, subkey2 = random.split(key, 3)\n",
    "    X = sample_mvn(subkey1, mean1, cov1, (10,))\n",
    "    Y = sample_mvn(subkey2, mean2, cov2, (10,))\n",
    "    Kxx, Kyy, Kxy = compute_K_matrices(X, Y, sigma0)\n",
    "\n",
    "    mmd_value = compute_mmd_sq(Kxx, Kyy, Kxy, N, N)\n",
    "    mmd_samples = mmd_samples.at[i].set(mmd_value)\n",
    "\n",
    "    true_variance = jnp.var(mmd_samples, ddof=1)\n",
    "    true_variances.append(true_variance)\n",
    "\n",
    "    start_time = time.time()\n",
    "    method1_variance = MMDVar(X, Y, sigma0) # Full Variance Estimate\n",
    "    method1_variances.append(method1_variance)\n",
    "    method1_time = time.time() - start_time\n",
    "    method1_times.append(method1_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    method2_variance = MMDVar(X, Y, sigma0, complete=False) # Complete Variance Estimate\n",
    "    method2_variances.append(method2_variance)\n",
    "    method2_time = time.time() - start_time\n",
    "    method2_times.append(method2_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    method3_variance = h1_mean_var_gram(Kxx, Kyy, Kxy, is_var_computed=True, use_1sample_U=True)[1]\n",
    "    method3_variances.append(method3_variance)\n",
    "    method3_time = time.time() - start_time\n",
    "    method3_times.append(method3_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    method4_variance = MMDu_var(Kxx, Kyy, Kxy)\n",
    "    method4_variances.append(method4_variance)\n",
    "    method4_time = time.time() - start_time\n",
    "    method4_times.append(method4_time)\n",
    "\n",
    "# Display results\n",
    "for N, t1, t2, t3, t4 in zip(num_samples, method1_times, method2_times, method3_times, method4_times):\n",
    "    print(f\"Sample Size {N}:\")\n",
    "    print(f\"Full Variance Estimate(Ours 8) Time: {t1:.4f} seconds\")\n",
    "    print(f\"Complete Variance Estimate(Ours 2) Time: {t2:.4f} seconds\")\n",
    "    print(f\"Deep MMD(Liu et al. 2) Time: {t3:.4f} seconds\")\n",
    "    print(f\"Complete Variance Estimate using h(Ours 2) Time: {t4:.4f} seconds\")\n",
    "    print()\n",
    "\n",
    "# Visualization\n",
    "plt.plot(num_samples, true_variances, label='True Variance')\n",
    "plt.plot(num_samples, method1_variances, label='Full Variance Estimate(Ours 8)')\n",
    "plt.plot(num_samples, method2_variances, label='Complete Variance Estimate(Ours 2)')\n",
    "plt.plot(num_samples, method3_variances, label='Deep MMD (Liu et al. 2)')\n",
    "plt.plot(num_samples, method4_variances, label='Complete Variance Estimate using h(Ours 2)')\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('Variance')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "\n",
    "# First dataset\n",
    "mean1 = jnp.zeros()\n",
    "cov1 = jnp.eye(100)\n",
    "\n",
    "# Second dataset\n",
    "mean2 = jnp.ones(100)\n",
    "cov2 = jnp.eye(100)\n",
    "cov2 = cov2.at[3, 4].set(0.3)\n",
    "cov2 = cov2.at[4, 3].set(0.5)\n",
    "\n",
    "# Function to generate samples from multivariate normal distribution\n",
    "def sample_mvn(key, mean, cov, num_samples):\n",
    "    return multivariate_normal(mean=mean, cov=cov, shape=num_samples, key=key)\n",
    "\n",
    "# Number of times to estimate MMD\n",
    "num_samples = 10000\n",
    "\n",
    "# Array to store MMD values\n",
    "mmd_samples = jnp.zeros(num_samples)\n",
    "sigma0 = 1\n",
    "\n",
    "# Monte Carlo simulation to estimate MMD values\n",
    "for i in range(num_samples):\n",
    "    key, subkey1, subkey2 = random.split(key, 3)\n",
    "    X = sample_mvn(subkey1, mean1, cov1, (200,))\n",
    "    Y = sample_mvn(subkey2, mean2, cov2, (200,))\n",
    "\n",
    "    Kxx, Kyy, Kxy = compute_K_matrices(X, Y, sigma0)\n",
    "    mmd_value = compute_mmd_sq(Kxx, Kyy, Kxy, len(X), len(Y))\n",
    "\n",
    "    mmd_samples = mmd_samples.at[i].set(mmd_value)\n",
    "\n",
    "# Compute estimated variance of MMD\n",
    "mmd_variance = jnp.var(mmd_samples, ddof=1)\n",
    "\n",
    "print(\"True Variance of MMD:\", mmd_variance)\n",
    "\n",
    "# Compare the results\n",
    "print(f\"Full Variance Estimate (Ours 8): {MMDVar(X, Y, sigma0)}\")\n",
    "print(f\"Complete Variance Estimate (Ours 2): {MMDVar(X, Y, sigma0, complete=False)}\")\n",
    "print(f\"Complete Variance Estimate using h (Ours 2): {MMDu_var(Kxx, Kyy, Kxy)}\")\n",
    "print(f\"Incomplete Variance Estimate (Liu et al. 2): {h1_mean_var_gram(Kxx, Kyy, Kxy, is_var_computed=True, use_1sample_U=True)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c2st",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
