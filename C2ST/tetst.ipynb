{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms \n",
    "from data_aug.gaussian_blur import GaussianBlur\n",
    "from torchvision import transforms, datasets\n",
    "from data_aug.view_generator import ContrastiveLearningViewGenerator\n",
    "from data_aug.contrastive_learning_dataset import ContrastiveLearningDataset\n",
    "from exceptions.exceptions import InvalidDatasetSelection\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simclr_pipeline_transform(size, s=1):\n",
    "        \"\"\"Return a list of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
    "        color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "        data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
    "                                                transforms.RandomHorizontalFlip(),\n",
    "                                                transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                                transforms.RandomGrayscale(p=0.2),\n",
    "                                                GaussianBlur(kernel_size=int(0.1*size)),\n",
    "                                                transforms.ToTensor()])\n",
    "        return data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ContrastiveLearningViewGenerator(\n",
    "                                                                    self.get_simclr_pipeline_transform(32),\n",
    "                                                                    n_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Configure data loader\n",
    "dataset_test = datasets.CIFAR10(root='/data4/oldrain123/C2ST/data/cifar_data/cifar10', download=True,\n",
    "                                train=False,\n",
    "                           transform=ContrastiveLearningViewGenerator(\n",
    "                            get_simclr_pipeline_transform(32),\n",
    "                            2))\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=len(dataset_test), shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain CIFAR10 images\n",
    "for i, (imgs, Labels) in enumerate(dataloader_test):\n",
    "    data_all = imgs\n",
    "    label_all = Labels\n",
    "Ind_all = np.arange(len(data_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain CIFAR10.1 images\n",
    "data_new = np.load('/data4/oldrain123/C2ST/data/cifar_data/cifar10.1_v4_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_T = np.transpose(data_new, [0,3,1,2])\n",
    "TT = transforms.Compose(ContrastiveLearningViewGenerator(\n",
    "                            get_simclr_pipeline_transform(32),\n",
    "                            2))\n",
    "trans = transforms.ToPILImage()\n",
    "data_trans = torch.zeros([len(data_T),3,32,32])\n",
    "data_T_tensor = torch.from_numpy(data_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[230, 219, 216],\n",
       "         [237, 218, 211],\n",
       "         [236, 218, 215],\n",
       "         ...,\n",
       "         [159, 120, 116],\n",
       "         [198, 155, 140],\n",
       "         [213, 181, 167]],\n",
       "\n",
       "        [[237, 220, 212],\n",
       "         [251, 214, 206],\n",
       "         [251, 213, 209],\n",
       "         ...,\n",
       "         [ 79,  33,  26],\n",
       "         [147,  77,  67],\n",
       "         [181, 126, 112]],\n",
       "\n",
       "        [[240, 217, 209],\n",
       "         [255, 209, 203],\n",
       "         [255, 210, 207],\n",
       "         ...,\n",
       "         [ 39,  16,  22],\n",
       "         [ 77,  27,  36],\n",
       "         [100,  63,  67]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[219, 212, 213],\n",
       "         [217, 210, 207],\n",
       "         [211, 213, 206],\n",
       "         ...,\n",
       "         [215, 211, 209],\n",
       "         [219, 210, 204],\n",
       "         [216, 209, 206]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [253, 255, 255],\n",
       "         ...,\n",
       "         [252, 255, 255],\n",
       "         [254, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [252, 253, 254],\n",
       "         [253, 253, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [253, 254, 255],\n",
       "         [254, 255, 254]]],\n",
       "\n",
       "\n",
       "       [[[141, 134, 115],\n",
       "         [127, 120, 102],\n",
       "         [122, 115,  96],\n",
       "         ...,\n",
       "         [150, 143, 127],\n",
       "         [146, 139, 123],\n",
       "         [144, 137, 120]],\n",
       "\n",
       "        [[145, 138, 119],\n",
       "         [139, 132, 114],\n",
       "         [129, 122, 104],\n",
       "         ...,\n",
       "         [146, 139, 123],\n",
       "         [146, 139, 123],\n",
       "         [146, 139, 123]],\n",
       "\n",
       "        [[142, 135, 116],\n",
       "         [140, 133, 115],\n",
       "         [140, 133, 115],\n",
       "         ...,\n",
       "         [150, 143, 127],\n",
       "         [146, 139, 123],\n",
       "         [145, 138, 122]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[155, 149, 137],\n",
       "         [144, 138, 126],\n",
       "         [132, 126, 114],\n",
       "         ...,\n",
       "         [127, 120, 102],\n",
       "         [129, 122, 104],\n",
       "         [132, 125, 106]],\n",
       "\n",
       "        [[149, 143, 131],\n",
       "         [145, 139, 127],\n",
       "         [146, 140, 128],\n",
       "         ...,\n",
       "         [135, 128, 110],\n",
       "         [127, 120, 102],\n",
       "         [133, 126, 107]],\n",
       "\n",
       "        [[158, 152, 140],\n",
       "         [162, 156, 144],\n",
       "         [155, 149, 137],\n",
       "         ...,\n",
       "         [136, 129, 110],\n",
       "         [134, 126, 109],\n",
       "         [139, 131, 114]]],\n",
       "\n",
       "\n",
       "       [[[ 59,  66,  47],\n",
       "         [ 43,  54,  35],\n",
       "         [ 32,  48,  20],\n",
       "         ...,\n",
       "         [ 72,  75,  54],\n",
       "         [ 51,  54,  35],\n",
       "         [ 54,  55,  38]],\n",
       "\n",
       "        [[ 67,  79,  58],\n",
       "         [ 68,  81,  60],\n",
       "         [ 44,  61,  33],\n",
       "         ...,\n",
       "         [121, 124, 104],\n",
       "         [ 72,  75,  57],\n",
       "         [ 51,  52,  38]],\n",
       "\n",
       "        [[117, 130, 107],\n",
       "         [116, 130, 106],\n",
       "         [ 98, 113,  86],\n",
       "         ...,\n",
       "         [150, 153, 135],\n",
       "         [ 70,  73,  58],\n",
       "         [ 38,  39,  25]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[209, 213, 212],\n",
       "         [200, 201, 199],\n",
       "         [167, 166, 161],\n",
       "         ...,\n",
       "         [175, 176, 173],\n",
       "         [173, 174, 172],\n",
       "         [171, 172, 168]],\n",
       "\n",
       "        [[198, 200, 198],\n",
       "         [205, 206, 202],\n",
       "         [174, 174, 169],\n",
       "         ...,\n",
       "         [190, 191, 182],\n",
       "         [200, 201, 192],\n",
       "         [204, 204, 193]],\n",
       "\n",
       "        [[170, 170, 167],\n",
       "         [179, 180, 176],\n",
       "         [175, 176, 172],\n",
       "         ...,\n",
       "         [192, 191, 179],\n",
       "         [199, 198, 185],\n",
       "         [202, 199, 187]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 30,  32,  30],\n",
       "         [ 21,  23,  22],\n",
       "         [ 27,  29,  25],\n",
       "         ...,\n",
       "         [ 17,  18,  19],\n",
       "         [ 30,  30,  29],\n",
       "         [ 42,  41,  33]],\n",
       "\n",
       "        [[ 18,  20,  22],\n",
       "         [ 22,  23,  23],\n",
       "         [ 32,  34,  30],\n",
       "         ...,\n",
       "         [ 16,  21,  19],\n",
       "         [ 22,  25,  23],\n",
       "         [ 33,  34,  29]],\n",
       "\n",
       "        [[ 10,  12,  14],\n",
       "         [ 13,  14,  14],\n",
       "         [ 30,  32,  29],\n",
       "         ...,\n",
       "         [ 15,  17,  16],\n",
       "         [ 16,  18,  18],\n",
       "         [ 30,  30,  28]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[196, 205, 203],\n",
       "         [ 75,  82,  84],\n",
       "         [ 62,  60,  65],\n",
       "         ...,\n",
       "         [238, 235, 225],\n",
       "         [149, 149, 140],\n",
       "         [ 28,  23,  19]],\n",
       "\n",
       "        [[119, 124, 123],\n",
       "         [ 71,  78,  76],\n",
       "         [109, 111, 112],\n",
       "         ...,\n",
       "         [210, 203, 195],\n",
       "         [133, 131, 123],\n",
       "         [ 16,  17,  16]],\n",
       "\n",
       "        [[149, 152, 153],\n",
       "         [180, 183, 180],\n",
       "         [232, 231, 227],\n",
       "         ...,\n",
       "         [215, 206, 197],\n",
       "         [119, 112, 105],\n",
       "         [ 26,  21,  20]]],\n",
       "\n",
       "\n",
       "       [[[138, 118,  94],\n",
       "         [143, 118,  97],\n",
       "         [147, 121, 102],\n",
       "         ...,\n",
       "         [128, 122, 106],\n",
       "         [125, 120, 106],\n",
       "         [ 99,  93,  81]],\n",
       "\n",
       "        [[136, 119,  94],\n",
       "         [139, 118,  98],\n",
       "         [142, 120, 102],\n",
       "         ...,\n",
       "         [108, 106,  92],\n",
       "         [113, 111,  99],\n",
       "         [ 77,  75,  64]],\n",
       "\n",
       "        [[133, 118,  97],\n",
       "         [128, 112,  97],\n",
       "         [123, 108,  92],\n",
       "         ...,\n",
       "         [ 81,  81,  71],\n",
       "         [ 83,  83,  75],\n",
       "         [ 44,  45,  38]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 28,  11,   9],\n",
       "         [ 33,   9,  13],\n",
       "         [ 22,   7,   9],\n",
       "         ...,\n",
       "         [ 23,  10,  13],\n",
       "         [ 22,  10,  12],\n",
       "         [ 20,  10,  12]],\n",
       "\n",
       "        [[ 22,  10,  11],\n",
       "         [ 23,   9,  15],\n",
       "         [ 17,   9,  11],\n",
       "         ...,\n",
       "         [ 19,  11,  13],\n",
       "         [ 19,  11,  13],\n",
       "         [ 18,  10,  12]],\n",
       "\n",
       "        [[ 17,  10,  13],\n",
       "         [ 16,  10,  17],\n",
       "         [ 12,  11,  14],\n",
       "         ...,\n",
       "         [ 15,  11,  12],\n",
       "         [ 16,  11,  12],\n",
       "         [ 15,  10,  12]]],\n",
       "\n",
       "\n",
       "       [[[130, 133, 145],\n",
       "         [121, 122, 142],\n",
       "         [115, 113, 133],\n",
       "         ...,\n",
       "         [114, 117, 121],\n",
       "         [126, 130, 131],\n",
       "         [134, 138, 140]],\n",
       "\n",
       "        [[138, 140, 152],\n",
       "         [134, 134, 152],\n",
       "         [133, 131, 149],\n",
       "         ...,\n",
       "         [144, 148, 148],\n",
       "         [162, 166, 164],\n",
       "         [160, 164, 163]],\n",
       "\n",
       "        [[145, 146, 157],\n",
       "         [132, 131, 146],\n",
       "         [136, 135, 149],\n",
       "         ...,\n",
       "         [172, 177, 174],\n",
       "         [176, 181, 177],\n",
       "         [167, 172, 169]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[141, 131, 122],\n",
       "         [131, 122, 113],\n",
       "         [130, 121, 112],\n",
       "         ...,\n",
       "         [106,  97,  90],\n",
       "         [101,  94,  89],\n",
       "         [111, 104,  97]],\n",
       "\n",
       "        [[131, 122, 113],\n",
       "         [132, 123, 114],\n",
       "         [136, 127, 117],\n",
       "         ...,\n",
       "         [108,  98,  89],\n",
       "         [104,  95,  87],\n",
       "         [108,  98,  92]],\n",
       "\n",
       "        [[132, 123, 114],\n",
       "         [137, 128, 119],\n",
       "         [135, 126, 117],\n",
       "         ...,\n",
       "         [114, 102,  94],\n",
       "         [111,  99,  90],\n",
       "         [117, 104,  96]]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCIFAR10_1(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.images = np.load(data_path, allow_pickle=True)  # Assuming this is the image data array\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_image = self.images[idx]\n",
    "\n",
    "        # Convert to PIL Image\n",
    "        sample_image = Image.fromarray(np.uint8(sample_image))\n",
    "\n",
    "        if self.transform:\n",
    "            sample_image = self.transform(sample_image)\n",
    "\n",
    "        return sample_image  # If you don't have labels, return just the image\n",
    "\n",
    "    \n",
    "class ContrastiveLearningDataset:\n",
    "    def __init__(self, root_folder):\n",
    "        self.root_folder = root_folder\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_simclr_pipeline_transform(size, s=1):\n",
    "        \"\"\"Return a list of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
    "        color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "        data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
    "                                                transforms.RandomHorizontalFlip(),\n",
    "                                                transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                                transforms.RandomGrayscale(p=0.2),\n",
    "                                                GaussianBlur(kernel_size=int(0.1*size)),\n",
    "                                                transforms.ToTensor()])\n",
    "        return data_transforms\n",
    "    \n",
    "    def get_dataset(self, name, n_views):\n",
    "        valid_datasets = {'cifar10' : lambda: datasets.CIFAR10(self.root_folder, train=False,\n",
    "                                                                transform = ContrastiveLearningViewGenerator(\n",
    "                                                                    self.get_simclr_pipeline_transform(32),\n",
    "                                                                    n_views),\n",
    "                                                                download=True),\n",
    "                        'stl10': lambda: datasets.STL10(self.root_finder, split='unlabeled',\n",
    "                                                        transform = ContrastiveLearningViewGenerator(\n",
    "                                                            self.get_simclr_pipeline_transform(96),\n",
    "                                                            n_views),\n",
    "                                                        download=True),\n",
    "                        'cifar10_1': lambda: CustomCIFAR10_1('/data4/oldrain123/C2ST/data/cifar_data/cifar10.1_v4_data.npy',\n",
    "                                                              transform=ContrastiveLearningViewGenerator(\n",
    "                                                                  self.get_simclr_pipeline_transform(32),\n",
    "                                                                  n_views))\n",
    "                        }\n",
    "        try:\n",
    "            dataset_fn = valid_datasets[name]\n",
    "        except KeyError:\n",
    "            raise InvalidDatasetSelection()\n",
    "        else:\n",
    "            return dataset_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset, Subset, DataLoader\n",
    "from random import sample\n",
    "\n",
    "root_folder = \"/data4/oldrain123/C2ST/data/cifar_data/cifar10\"\n",
    "\n",
    "class LabeledDataset(Dataset):\n",
    "    def __init__(self, base_dataset, label):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.base_dataset[idx]\n",
    "        return image, self.label\n",
    "\n",
    "# Initialize CIFAR10 and CIFAR10.1 datasets\n",
    "cifar10_dataset = datasets.CIFAR10(root_folder, train=False, transform=ContrastiveLearningViewGenerator(ContrastiveLearningDataset.get_simclr_pipeline_transform(32), n_views=2), download=True)\n",
    "cifar10_1_dataset = CustomCIFAR10_1('/data4/oldrain123/C2ST/data/cifar_data/cifar10.1_v4_data.npy', transform=ContrastiveLearningViewGenerator(ContrastiveLearningDataset.get_simclr_pipeline_transform(32), n_views=2))\n",
    "\n",
    "# Sample 2000 images from CIFAR10\n",
    "indices = sample(range(len(cifar10_dataset)), len(cifar10_1_dataset), )\n",
    "cifar10_subset = Subset(cifar10_dataset, indices)\n",
    "\n",
    "# Add labels\n",
    "labeled_cifar10 = LabeledDataset(cifar10_subset, 0)\n",
    "labeled_cifar10_1 = LabeledDataset(cifar10_1_dataset, 1)\n",
    "\n",
    "# Combine the two datasets\n",
    "combined_dataset = ConcatDataset([labeled_cifar10, labeled_cifar10_1])\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(combined_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cifar10_1_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
