{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils_HD import MatConvert, MMDu, TST_MMD_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(819)\n",
    "torch.manual_seed(819)\n",
    "torch.cuda.manual_seed(819)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "is_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Settings\n",
    "n_epochs = 1000\n",
    "batch_size = 100\n",
    "lr = 0.0002\n",
    "img_size = 64\n",
    "channels = 3\n",
    "n = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\")\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "N_per = 100 # permutation times\n",
    "alpha = 0.05 # test threshold\n",
    "N1 = n # number of samples in one set\n",
    "K = 10 # number of trails\n",
    "J = 1 # number of test locations\n",
    "N = 100 # number of test sets\n",
    "N_f = 100.0 # number of test sets (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming variables\n",
    "ep_OPT = np.zeros([K])\n",
    "s_OPT = np.zeros([K])\n",
    "s0_OPT = np.zeros([K])\n",
    "T_org_OPT = torch.zeros([K,J,3,64,64]) # Record test locations obtained by MMD-D\n",
    "COM_Results = np.zeros([1,K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deep network for MMD-D\n",
    "class Featurizer_COM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Featurizer_COM, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0)] #0.25\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(\n",
    "            nn.Linear(128 * ds_size ** 2, 300))\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        feature = self.adv_layer(out)\n",
    "\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Configure data loader\n",
    "dataset_test = datasets.CIFAR10(root='/data4/oldrain123/C2ST/data/cifar_data/cifar10', download=True,train=False,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=10000,\n",
    "                                             shuffle=True, num_workers=1)\n",
    "# Obtain CIFAR10 images\n",
    "for i, (imgs, Labels) in enumerate(dataloader_test):\n",
    "    data_all = imgs\n",
    "    label_all = Labels\n",
    "Ind_all = np.arange(len(data_all))\n",
    "\n",
    "# Obtain CIFAR10.1 images\n",
    "data_new = np.load('/data4/oldrain123/C2ST/data/cifar10_1/cifar10.1_v4_data.npy')\n",
    "data_T = np.transpose(data_new, [0,3,1,2])\n",
    "ind_M = np.random.choice(len(data_T), len(data_T), replace=False)\n",
    "data_T = data_T[ind_M]\n",
    "TT = transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trans = transforms.ToPILImage()\n",
    "data_trans = torch.zeros([len(data_T),3,img_size,img_size])\n",
    "data_T_tensor = torch.from_numpy(data_T)\n",
    "for i in range(len(data_T)):\n",
    "    d0 = trans(data_T_tensor[i])\n",
    "    data_trans[i] = TT(d0)\n",
    "Ind_v4_all = np.arange(len(data_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a2dfb0e72542168cd1fc96e781471e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de1f6e9fd524270aaa1ff2d284dc457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1120517/3630223948.py:57: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392035629/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
      "CUDA backend failed to initialize: Found cuPTI version 18, but JAX was built against version 20, which is newer. The copy of cuPTI that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret 'torch.float32' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/mmdenv/lib/python3.9/site-packages/jax/_src/api_util.py\u001b[0m in \u001b[0;36mshaped_abstractify\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    582\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_shaped_abstractify_handlers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: <class 'torch.Tensor'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1120517/3630223948.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0msigma0_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma0OPT\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;31m# Compute Compute J (STAT_u)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mCOM_TEMP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMMDu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom_modelu_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma0_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0mcom_mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOM_TEMP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mcom_mmd_std_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOM_TEMP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MMD/utils_HD.py\u001b[0m in \u001b[0;36mMMDu\u001b[0;34m(Fea, len_s, Fea_org, sigma, sigma0, epsilon, is_smooth, is_var_computed, use_1sample_U, complete)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mKy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mDyy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msigma0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mKxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mDxy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msigma0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh1_mean_var_gram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_var_computed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_1sample_U\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MMD/utils_HD.py\u001b[0m in \u001b[0;36mh1_mean_var_gram\u001b[0;34m(Kx, Ky, Kxy, is_var_computed, use_1sample_U, complete)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmmd2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKxyxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mhh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mKy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mKxy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mKxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0mhsic_xx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHSIC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0mhsic_yy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHSIC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mhsic_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHSIC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MMD/utils.py\u001b[0m in \u001b[0;36mHSIC\u001b[0;34m(Kxx, Kyy)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;34m\"\"\"Compute the Hilbert-Schmidt Independence Criterion.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mcentered_Kxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcenter_kernel_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mcentered_Kyy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcenter_kernel_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKyy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MMD/utils.py\u001b[0m in \u001b[0;36mcenter_kernel_matrix\u001b[0;34m(K)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mHSIC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKyy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmdenv/lib/python3.9/site-packages/jax/_src/dtypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_issubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_issubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_issubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtendedDType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtendedDType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret 'torch.float32' as a data type"
     ]
    }
   ],
   "source": [
    "# Repeat experiments K times (K = 10) and report average test power (rejection rate)\n",
    "for kk in tqdm(range(K)):\n",
    "    torch.manual_seed(kk * 19 + N1)\n",
    "    torch.cuda.manual_seed(kk * 19 + N1)\n",
    "    np.random.seed(seed=1102 * (kk + 10) + N1)\n",
    "    \n",
    "    # Initialize deep networks for MMD-D (called featurizer)\n",
    "    featurizer_com = Featurizer_COM()\n",
    "    \n",
    "    # Initialize parameters\n",
    "    epsilonOPT = torch.log(MatConvert(np.random.rand(1) * 10 ** (-10), device, dtype))\n",
    "    epsilonOPT.requires_grad = True\n",
    "    sigmaOPT = MatConvert(np.ones(1) * np.sqrt(2 * 32 * 32), device, dtype)\n",
    "    sigmaOPT.requires_grad = True\n",
    "    sigma0OPT = MatConvert(np.ones(1) * np.sqrt(0.005), device, dtype)\n",
    "    sigma0OPT.requires_grad = True\n",
    "    if cuda:\n",
    "        featurizer_com.cuda()\n",
    "\n",
    "    # Collect CIFAR10 images\n",
    "    Ind_tr = np.random.choice(len(data_all), N1, replace=False)\n",
    "    Ind_te = np.delete(Ind_all, Ind_tr)\n",
    "    train_data = []\n",
    "    for i in Ind_tr:\n",
    "       train_data.append([data_all[i], label_all[i]])\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Collect CIFAR10.1 images\n",
    "    np.random.seed(seed=819 * (kk + 9) + N1)\n",
    "    Ind_tr_v4 = np.random.choice(len(data_T), N1, replace=False)\n",
    "    Ind_te_v4 = np.delete(Ind_v4_all, Ind_tr_v4)\n",
    "    New_CIFAR_tr = data_trans[Ind_tr_v4]\n",
    "    New_CIFAR_te = data_trans[Ind_te_v4]\n",
    "\n",
    "    # Initialize optimizers\n",
    "    optimizer_COM = torch.optim.Adam(list(featurizer_com.parameters()) + [epsilonOPT] + [sigmaOPT] + [sigma0OPT], lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------------\n",
    "    #  Training deep networks for MMD-D (called featurizer)\n",
    "    # ----------------------------------------------------------------------------------------------------\n",
    "    np.random.seed(seed=1102)\n",
    "    torch.manual_seed(1102)\n",
    "    torch.cuda.manual_seed(1102)\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        for i, (imgs, _) in enumerate(dataloader):\n",
    "            if True:\n",
    "                ind = np.random.choice(N1, imgs.shape[0], replace=False)\n",
    "                Fake_imgs = New_CIFAR_tr[ind]\n",
    "                # Adversarial ground truths\n",
    "                valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "                fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "                # Configure input\n",
    "                real_imgs = Variable(imgs.type(Tensor))\n",
    "                Fake_imgs = Variable(Fake_imgs.type(Tensor))\n",
    "                X = torch.cat([real_imgs, Fake_imgs], 0)\n",
    "                Y = torch.cat([valid, fake], 0).squeeze().long()\n",
    "\n",
    "                # ------------------------------\n",
    "                #  Train deep network for MMD-D\n",
    "                # ------------------------------\n",
    "                # Initialize optimizer\n",
    "                optimizer_COM.zero_grad()\n",
    "                # Compute output of deep network\n",
    "                com_modelu_output = featurizer_com(X)\n",
    "                # Compute epsilon, sigma and sigma_0\n",
    "                ep = torch.exp(epsilonOPT) / (1 + torch.exp(epsilonOPT))\n",
    "                sigma = sigmaOPT ** 2\n",
    "                sigma0_u = sigma0OPT ** 2\n",
    "                # Compute Compute J (STAT_u)\n",
    "                COM_TEMP = MMDu(com_modelu_output, imgs.shape[0], X.view(X.shape[0],-1), sigma, sigma0_u, ep, complete=True)\n",
    "                com_mmd = COM_TEMP[0]\n",
    "                com_mmd_std_tmp = np.maximum(COM_TEMP[1], 10**(-10))\n",
    "                com_mmd_std_tmp_np = np.array(com_mmd_std_tmp) \n",
    "                com_mmd_std_tmp_tensor = torch.from_numpy(com_mmd_std_tmp_np).to(torch.float32)\n",
    "                # com_mmd_std = torch.sqrt(com_mmd_std_tmp_tensor + 10 ** (-8))\n",
    "                com_hsic_xx = torch.from_numpy(np.array(COM_TEMP[3])).to(torch.float32)\n",
    "                com_hsic_yy = torch.from_numpy(np.array(COM_TEMP[4])).to(torch.float32)\n",
    "                \n",
    "                com_mmd_std = torch.sqrt(com_mmd_std_tmp_tensor)\n",
    "                # com_mmd_std = com_mmd_std_tmp_tensor\n",
    "                COM_STAT_u = torch.div(com_mmd, com_mmd_std) + torch.sqrt(com_hsic_xx + com_hsic_yy)\n",
    "                # COM_STAT_u = - torch.log(com_mmd) + torch.log(com_mmd_std)\n",
    "                # if COM_TEMP[1] < 0:\n",
    "                #     COM_STAT_u = - torch.abs(COM_STAT_u)                \n",
    "                \n",
    "                if (epoch+1) % 100 == 0:\n",
    "                    print(\"=\" * 110)\n",
    "                    print(\"epoch : \",epoch+1)\n",
    "                    print(\"our mmd: \", -1 * com_mmd.item(), \"our mmd_std: \", com_mmd_std.item(), \"our statistic: \",\n",
    "                    -1 * COM_STAT_u.item())\n",
    "                    \n",
    "                # Compute gradient\n",
    "                COM_STAT_u.backward()\n",
    "                \n",
    "                # Update weights using gradient descent\n",
    "                optimizer_COM.step()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # Run two-sample test on the training set\n",
    "    # Fetch training data\n",
    "    s1 = data_all[Ind_tr]\n",
    "    s2 = data_trans[Ind_tr_v4]\n",
    "    S = torch.cat([s1.cpu(), s2.cpu()], 0).cuda()\n",
    "    Sv = S.view(2 * N1, -1)\n",
    "    # Run two-sample test (MMD-D) on the training set\n",
    "    # dk_h_u, dk_threshold_u, dk_mmd_value_u = TST_MMD_u(featurizer(S), N_per, N1, Sv, sigma, sigma0_u, ep, alpha, device, dtype, complete=False)\n",
    "    # com_h_u, com_threshold_u, com_mmd_value_u = TST_MMD_u(featurizer(S), N_per, N1, Sv, sigma, sigma0_u, ep, alpha, device, dtype, complete=True)\n",
    "\n",
    "    # Record best epsilon, sigma and sigma_0\n",
    "    ep_OPT[kk] = ep.item()\n",
    "    s_OPT[kk] = sigma.item()\n",
    "    s0_OPT[kk] = sigma0_u.item()\n",
    "\n",
    "    # Compute test power of MMD-D and baselines\n",
    "    DK_H_u = np.zeros(N)\n",
    "    COM_H_u = np.zeros(N)\n",
    "\n",
    "    np.random.seed(1102)\n",
    "    dk_count_u = 0\n",
    "    com_count_u = 0\n",
    "\n",
    "    for k in tqdm(range(N)):\n",
    "        # Fetch test data\n",
    "        np.random.seed(seed=1102 * (k + 1) + N1)\n",
    "        data_all_te = data_all[Ind_te]\n",
    "        N_te = len(data_trans)-N1\n",
    "        Ind_N_te = np.random.choice(len(Ind_te), N_te, replace=False)\n",
    "        s1 = data_all_te[Ind_N_te]\n",
    "        s2 = data_trans[Ind_te_v4]\n",
    "        S = torch.cat([s1.cpu(), s2.cpu()], 0).cuda()\n",
    "        Sv = S.view(2 * N_te, -1)\n",
    "        # MMD-D\n",
    "        com_h_u, com_threshold_u, com_mmd_value_u = TST_MMD_u(featurizer_com(S), N_per, N_te, Sv, sigma, sigma0_u, ep, alpha, device, dtype, complete=True)\n",
    "\n",
    "        # Gather results\n",
    "        com_count_u = com_count_u + com_h_u\n",
    "        print(\"\\r\",\"Ours:\", com_count_u, \"MMD: \", com_mmd_value_u, end=\"\")\n",
    "        COM_H_u[k] = com_h_u\n",
    "\n",
    "    # Print test power of MMD-D and baselines\n",
    "    print(\"Our Reject rate_u: \", COM_H_u.sum() / N_f)\n",
    "    COM_Results[0, kk] = COM_H_u.sum() / N_f\n",
    "    print(f\"Test Power of Ours ({K} times): \")\n",
    "    print(f\"{COM_Results}\")\n",
    "    print(f\"Average Test Power of Ours ({K} times): \")\n",
    "    print(\"Ours: \", (COM_Results.sum(1) / (kk + 1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epoch 20 / lr: 0.0005\n",
    "[[0.23 0.94 0.25 0.37 0.6  0.1  0.36 0.31 0.23 0.4 ]\n",
    " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
    "Average Test Power of Baselines (10 times): \n",
    "MMD-D:  0.379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
