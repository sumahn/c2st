{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('/home/oldrain123/MMD/')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from utils_HD import MatConvert, MMDu, TST_MMD_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLatentF(torch.nn.Module):\n",
    "    \"\"\"Latent space for both domains.\"\"\"\n",
    "\n",
    "    def __init__(self, x_in, H, x_out):\n",
    "        \"\"\"Init latent features.\"\"\"\n",
    "        super(ModelLatentF, self).__init__()\n",
    "        self.restored = False\n",
    "\n",
    "        self.latent = torch.nn.Sequential(\n",
    "            torch.nn.Linear(x_in, H, bias=True),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(H, x_out, bias=True),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward the LeNet.\"\"\"\n",
    "        fealant = self.latent(input)\n",
    "        return fealant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "np.random.seed(1102)\n",
    "torch.manual_seed(1102)\n",
    "torch.cuda.manual_seed(1102)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "is_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 8000 d: 4\n"
     ]
    }
   ],
   "source": [
    "# Setup for experiments\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\")\n",
    "N_per = 100 # permutation times\n",
    "alpha = 0.05 # test threshold\n",
    "d = 4 # dimension of data\n",
    "n = 8000\n",
    "print('n: '+str(n)+' d: '+str(d))\n",
    "N_epoch = 1000 # number of training epochs\n",
    "x_in = d # number of neurons in the input layer, i.e., dimension of data\n",
    "H = 20 # number of neurons in the hidden layer\n",
    "x_out = 20 # number of neurons in the output layer\n",
    "learning_rate = 0.00005\n",
    "learning_ratea = 0.001\n",
    "learning_rate_C2ST = 0.001\n",
    "K = 10 # number of trails\n",
    "N = 100 # number of test sets\n",
    "N_f = 100.0 # number of test sets (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pickle.load(open('/data4/oldrain123/C2ST/data/HIGGS/HIGGS_TST.pckl', 'rb'))\n",
    "dataX = data[0]\n",
    "dataY = data[1]\n",
    "# REPLACE above two lines with\n",
    "# dataX = data[0]\n",
    "# dataY = data[0]\n",
    "# or\n",
    "# dataX = data[1]\n",
    "# dataY = data[1]\n",
    "# for validating type-I error\n",
    "del data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming variables\n",
    "J_star_u = np.zeros([N_epoch])\n",
    "J_star_adp = np.zeros([N_epoch])\n",
    "ep_OPT = np.zeros([K])\n",
    "s_OPT = np.zeros([K])\n",
    "s0_OPT = np.zeros([K])\n",
    "Results = np.zeros([1,K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:  0.0002224743366241455 mmd_std:  0.003164449377443643 Statistic:  0.07030428048871755\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 243.00 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 9.26 GiB is allocated by PyTorch, and 120.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2199979/2386818718.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mmodelu_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# Compute J (STAT_u)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mTEMP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMMDu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelu_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma0_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mmmd_value_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTEMP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 10**(-8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mmmd_std_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEMP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MMD/utils_HD.py\u001b[0m in \u001b[0;36mMMDu\u001b[0;34m(Fea, len_s, Fea_org, sigma, sigma0, epsilon, is_smooth, is_var_computed, use_1sample_U, complete)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mKy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mDyy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msigma0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mKxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mDxy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msigma0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh1_mean_var_gram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_var_computed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_1sample_U\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MMD/utils_HD.py\u001b[0m in \u001b[0;36mh1_mean_var_gram\u001b[0;34m(Kx, Ky, Kxy, is_var_computed, use_1sample_U, complete)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mtKxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtKyy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mtKxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtKxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mtKyy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtKyy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 243.00 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 9.26 GiB is allocated by PyTorch, and 120.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Repeat experiments K times (K = 10) and report average test power (rejection rate)\n",
    "for kk in range(K):\n",
    "    torch.manual_seed(kk * 19 + n)\n",
    "    torch.cuda.manual_seed(kk * 19 + n)\n",
    "    # Initialize parameters\n",
    "    if is_cuda:\n",
    "        model_u = ModelLatentF(x_in, H, x_out).cuda()\n",
    "    else:\n",
    "        model_u = ModelLatentF(x_in, H, x_out)\n",
    "    epsilonOPT = torch.log(MatConvert(np.random.rand(1) * 10 ** (-10), device, dtype))\n",
    "    epsilonOPT.requires_grad = True\n",
    "    sigmaOPT = MatConvert(np.ones(1) * np.sqrt(2*d), device, dtype)  # d = 3,5 ??\n",
    "    sigmaOPT.requires_grad = True\n",
    "    sigma0OPT = MatConvert(np.ones(1) * np.sqrt(0.005), device, dtype)\n",
    "    sigma0OPT.requires_grad = False\n",
    "    # print(epsilonOPT.item())\n",
    "\n",
    "    # Setup optimizer for training deep kernel\n",
    "    optimizer_u = torch.optim.Adam(list(model_u.parameters()) + [epsilonOPT] + [sigmaOPT] + [sigma0OPT], lr=learning_rate)\n",
    "\n",
    "    # Generate Higgs (P,Q)\n",
    "    N1_T = dataX.shape[0]\n",
    "    N2_T = dataY.shape[0]\n",
    "    np.random.seed(seed=1102 * kk + n)\n",
    "    ind1 = np.random.choice(N1_T, n, replace=False)\n",
    "    np.random.seed(seed=819 * kk + n)\n",
    "    ind2 = np.random.choice(N2_T, n, replace=False)\n",
    "    s1 = dataX[ind1,:4]\n",
    "    s2 = dataY[ind2,:4]\n",
    "    N1 = n\n",
    "    N2 = n\n",
    "    S = np.concatenate((s1, s2), axis=0)\n",
    "    S = MatConvert(S, device, dtype)\n",
    "\n",
    "    # Train deep kernel to maximize test power\n",
    "    for t in range(N_epoch):\n",
    "        # Compute epsilon, sigma and sigma_0\n",
    "        ep = torch.exp(epsilonOPT) / (1 + torch.exp(epsilonOPT))  # 10 ** (-10)#\n",
    "        sigma = sigmaOPT ** 2\n",
    "        sigma0_u = sigma0OPT ** 2\n",
    "        \n",
    "        optimizer_u.zero_grad() \n",
    "        \n",
    "        with autocast():        \n",
    "            # Compute output of the deep network\n",
    "            modelu_output = model_u(S)\n",
    "            # Compute J (STAT_u)\n",
    "            TEMP = MMDu(modelu_output, N1, S, sigma, sigma0_u, ep, complete=True)\n",
    "            mmd_value_temp = -1 * (TEMP[0])  # 10**(-8)\n",
    "            mmd_std_temp = torch.sqrt(TEMP[1]+10**(-5))  # 0.1\n",
    "            \n",
    "            STAT_u = torch.div(mmd_value_temp, mmd_std_temp)\n",
    "        J_star_u[t] = STAT_u.item()\n",
    "        # Initialize optimizer and Compute gradient\n",
    "        scaler.scale(STAT_u).backward()\n",
    "        scaler.step(optimizer_u)\n",
    "        scaler.update()\n",
    "        # Print MMD, std of MMD and J\n",
    "        if t % 100 ==0:\n",
    "            print(\"mmd: \", -1 * mmd_value_temp.item(), \"mmd_std: \", mmd_std_temp.item(), \"Statistic: \",\n",
    "                  -1 * STAT_u.item())  # ,\"Reg: \", loss1.item()\n",
    "\n",
    "    h_u, threshold_u, mmd_value_u = TST_MMD_u(model_u(S), N_per, N1, S, sigma, sigma0_u, ep, alpha, device, dtype, complete=True)\n",
    "    print(\"h:\", h_u, \"Threshold:\", threshold_u, \"MMD_value:\", mmd_value_u)\n",
    "    ep_OPT[kk] = ep.item()\n",
    "    s_OPT[kk] = sigma.item()\n",
    "    s0_OPT[kk] = sigma0_u.item()\n",
    "\n",
    "    # Compute test power of deep kernel based MMD\n",
    "    H_u = np.zeros(N)\n",
    "    T_u = np.zeros(N)\n",
    "    M_u = np.zeros(N)\n",
    "    np.random.seed(1102)\n",
    "    count_u = 0\n",
    "    for k in range(N):\n",
    "        # Generate Higgs (P,Q)\n",
    "        np.random.seed(seed=1102 * (k+1) + n)\n",
    "        ind1 = np.random.choice(N1_T, n, replace=False)\n",
    "        np.random.seed(seed=819 * (k+2) + n)\n",
    "        ind2 = np.random.choice(N2_T, n, replace=False)\n",
    "        s1 = dataX[ind1, :4]\n",
    "        s2 = dataY[ind2, :4]\n",
    "        S = np.concatenate((s1, s2), axis=0)\n",
    "        S = MatConvert(S, device, dtype)\n",
    "\n",
    "        # Run two sample test (deep kernel) on generated data\n",
    "        h_u, threshold_u, mmd_value_u = TST_MMD_u(model_u(S), N_per, N1, S, sigma, sigma0_u, ep, alpha, device, dtype, complete=True)\n",
    "\n",
    "        # Gather results\n",
    "        count_u = count_u + h_u\n",
    "        print(\"MMD-DK:\", count_u, \"Threshold:\", threshold_u, \"MMD_value:\", mmd_value_u)\n",
    "        H_u[k] = h_u\n",
    "        T_u[k] = threshold_u\n",
    "        M_u[k] = mmd_value_u\n",
    "    # Print test power of MMD-D\n",
    "    print(\"Test Power of MMD-D: \", H_u.sum() / N_f)\n",
    "    Results[0, kk] = H_u.sum() / N_f\n",
    "    print(\"Test Power of MMD-D (K times): \", Results[0])\n",
    "    print(\"Average Test Power of MMD-D: \", Results[0].sum() / (kk + 1))\n",
    "np.save('./Results_HIGGS_n' + str(n) + '_H1_MMD-D', Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Repeat experiments K times (K = 10) and report average test power (rejection rate)\n",
    "for kk in range(K):\n",
    "    torch.manual_seed(kk * 19 + n)\n",
    "    torch.cuda.manual_seed(kk * 19 + n)\n",
    "    # Initialize parameters\n",
    "    if is_cuda:\n",
    "        model_u = ModelLatentF(x_in, H, x_out).cuda()\n",
    "    else:\n",
    "        model_u = ModelLatentF(x_in, H, x_out)\n",
    "    epsilonOPT = torch.log(MatConvert(np.random.rand(1) * 10 ** (-10), device, dtype))\n",
    "    epsilonOPT.requires_grad = True\n",
    "    sigmaOPT = MatConvert(np.ones(1) * np.sqrt(2*d), device, dtype)  # d = 3,5 ??\n",
    "    sigmaOPT.requires_grad = True\n",
    "    sigma0OPT = MatConvert(np.ones(1) * np.sqrt(0.005), device, dtype)\n",
    "    sigma0OPT.requires_grad = False\n",
    "    # print(epsilonOPT.item())\n",
    "\n",
    "    # Setup optimizer for training deep kernel\n",
    "    optimizer_u = torch.optim.Adam(list(model_u.parameters()) + [epsilonOPT] + [sigmaOPT] + [sigma0OPT], lr=learning_rate)\n",
    "\n",
    "    # Generate Higgs (P,Q)\n",
    "    N1_T = dataX.shape[0]\n",
    "    N2_T = dataY.shape[0]\n",
    "    np.random.seed(seed=1102 * kk + n)\n",
    "    ind1 = np.random.choice(N1_T, n, replace=False)\n",
    "    np.random.seed(seed=819 * kk + n)\n",
    "    ind2 = np.random.choice(N2_T, n, replace=False)\n",
    "    s1 = dataX[ind1,:4]\n",
    "    s2 = dataY[ind2,:4]\n",
    "    N1 = n\n",
    "    N2 = n\n",
    "    S = np.concatenate((s1, s2), axis=0)\n",
    "    S = MatConvert(S, device, dtype)\n",
    "\n",
    "    # Train deep kernel to maximize test power\n",
    "    for t in range(N_epoch):\n",
    "        # Compute epsilon, sigma and sigma_0\n",
    "        ep = torch.exp(epsilonOPT) / (1 + torch.exp(epsilonOPT))  # 10 ** (-10)#\n",
    "        sigma = sigmaOPT ** 2\n",
    "        sigma0_u = sigma0OPT ** 2\n",
    "        # Compute output of the deep network\n",
    "        modelu_output = model_u(S)\n",
    "        # Compute J (STAT_u)\n",
    "        TEMP = MMDu(modelu_output, N1, S, sigma, sigma0_u, ep, complete=True)\n",
    "        mmd_value_temp = -1 * (TEMP[0])  # 10**(-8)\n",
    "        mmd_std_temp = torch.sqrt(TEMP[1]+10**(-5))  # 0.1\n",
    "        # if mmd_std_temp.item() == 0:\n",
    "        #     print('error!!')\n",
    "        # if np.isnan(mmd_std_temp.item()):\n",
    "        #     print('error!!')\n",
    "        STAT_u = torch.div(mmd_value_temp, mmd_std_temp)\n",
    "        J_star_u[t] = STAT_u.item()\n",
    "        # Initialize optimizer and Compute gradient\n",
    "        optimizer_u.zero_grad()\n",
    "        STAT_u.backward(retain_graph=True)\n",
    "        # Update weights using gradient descent\n",
    "        optimizer_u.step()\n",
    "        # Print MMD, std of MMD and J\n",
    "        if t % 100 ==0:\n",
    "            print(\"mmd: \", -1 * mmd_value_temp.item(), \"mmd_std: \", mmd_std_temp.item(), \"Statistic: \",\n",
    "                  -1 * STAT_u.item())  # ,\"Reg: \", loss1.item()\n",
    "\n",
    "    h_u, threshold_u, mmd_value_u = TST_MMD_u(model_u(S), N_per, N1, S, sigma, sigma0_u, ep, alpha, device, dtype, complete=True)\n",
    "    print(\"h:\", h_u, \"Threshold:\", threshold_u, \"MMD_value:\", mmd_value_u)\n",
    "    ep_OPT[kk] = ep.item()\n",
    "    s_OPT[kk] = sigma.item()\n",
    "    s0_OPT[kk] = sigma0_u.item()\n",
    "\n",
    "    # Compute test power of deep kernel based MMD\n",
    "    H_u = np.zeros(N)\n",
    "    T_u = np.zeros(N)\n",
    "    M_u = np.zeros(N)\n",
    "    np.random.seed(1102)\n",
    "    count_u = 0\n",
    "    for k in range(N):\n",
    "        # Generate Higgs (P,Q)\n",
    "        np.random.seed(seed=1102 * (k+1) + n)\n",
    "        ind1 = np.random.choice(N1_T, n, replace=False)\n",
    "        np.random.seed(seed=819 * (k+2) + n)\n",
    "        ind2 = np.random.choice(N2_T, n, replace=False)\n",
    "        s1 = dataX[ind1, :4]\n",
    "        s2 = dataY[ind2, :4]\n",
    "        S = np.concatenate((s1, s2), axis=0)\n",
    "        S = MatConvert(S, device, dtype)\n",
    "\n",
    "        # Run two sample test (deep kernel) on generated data\n",
    "        h_u, threshold_u, mmd_value_u = TST_MMD_u(model_u(S), N_per, N1, S, sigma, sigma0_u, ep, alpha, device, dtype, complete=True)\n",
    "\n",
    "        # Gather results\n",
    "        count_u = count_u + h_u\n",
    "        print(\"MMD-DK:\", count_u, \"Threshold:\", threshold_u, \"MMD_value:\", mmd_value_u)\n",
    "        H_u[k] = h_u\n",
    "        T_u[k] = threshold_u\n",
    "        M_u[k] = mmd_value_u\n",
    "    # Print test power of MMD-D\n",
    "    print(\"Test Power of MMD-D: \", H_u.sum() / N_f)\n",
    "    Results[0, kk] = H_u.sum() / N_f\n",
    "    print(\"Test Power of MMD-D (K times): \", Results[0])\n",
    "    print(\"Average Test Power of MMD-D: \", Results[0].sum() / (kk + 1))\n",
    "np.save('./Results_HIGGS_n' + str(n) + '_H1_MMD-D', Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_mmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
