{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('/home/oldrain123/MMD/')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "from utils_HD import MatConvert, MMDu, TST_MMD_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLatentF(torch.nn.Module):\n",
    "    \"\"\"Latent space for both domains.\"\"\"\n",
    "\n",
    "    def __init__(self, x_in, H, x_out):\n",
    "        \"\"\"Init latent features.\"\"\"\n",
    "        super(ModelLatentF, self).__init__()\n",
    "        self.restored = False\n",
    "\n",
    "        self.latent = torch.nn.Sequential(\n",
    "            torch.nn.Linear(x_in, H, bias=True),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(H, x_out, bias=True),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward the LeNet.\"\"\"\n",
    "        fealant = self.latent(input)\n",
    "        return fealant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "np.random.seed(1102)\n",
    "torch.manual_seed(1102)\n",
    "torch.cuda.manual_seed(1102)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "is_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for experiments\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\")\n",
    "N_per = 200 # permutation times\n",
    "alpha = 0.05 # test threshold\n",
    "n = 4000 \n",
    "d = 10\n",
    "x_in = d\n",
    "H = 3*d \n",
    "x_out = 3*d\n",
    "learning_rate = 0.00005\n",
    "N_epoch = 1000 # number of training epochs\n",
    "K = 10 # number of trails\n",
    "N = 100 # number of test sets\n",
    "N_f = 100.0 # number of test sets (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate variance and co-variance matrix of Q \n",
    "Num_clusters = 2 \n",
    "mu_mx = np.zeros([Num_clusters, d])\n",
    "mu_mx[1] = mu_mx[1] + 0.5\n",
    "sigma_mx_1 = np.identity(d) \n",
    "sigma_mx_2 = [np.identity(d), np.identity(d)]\n",
    "sigma_mx_2[0][0,1] = 0.5\n",
    "sigma_mx_2[0][1,0] = 0.5\n",
    "sigma_mx_2[1][0,1] = -0.5\n",
    "sigma_mx_2[1][1,0] = -0.5\n",
    "s1 = np.zeros([n*Num_clusters, d])\n",
    "s2 = np.zeros([n*Num_clusters, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming variables \n",
    "Results = np.zeros([1,K])\n",
    "J_star_u = np.zeros([N_epoch])\n",
    "J_star_adp = np.zeros([N_epoch])\n",
    "ep_OPT = np.zeros([K])\n",
    "s_OPT = np.zeros([K])\n",
    "s0_OPT = np.zeros([K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba95c3eaa3a420685ed3ccfa07c4065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Experiment:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd_value:  3.55839729309082e-05 mmd_std:  0.003162210127555641 Statistic:  0.011252880578943147\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 129.00 MiB is free. Process 760606 has 602.00 MiB memory in use. Including non-PyTorch memory, this process has 22.96 GiB memory in use. Of the allocated memory 8.79 GiB is allocated by PyTorch, and 115.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1558480/2845721390.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mmodelu_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# Compute J (STAT_u)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mTEMP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMMDu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelu_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma0_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mmmd_value_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTEMP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mmmd_std_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEMP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MMD/utils_HD.py\u001b[0m in \u001b[0;36mMMDu\u001b[0;34m(Fea, len_s, Fea_org, sigma, sigma0, epsilon, is_smooth, is_var_computed, use_1sample_U, complete)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mKy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mDyy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msigma0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mKxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mDxy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msigma0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh1_mean_var_gram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_var_computed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_1sample_U\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MMD/utils_HD.py\u001b[0m in \u001b[0;36mh1_mean_var_gram\u001b[0;34m(Kx, Ky, Kxy, is_var_computed, use_1sample_U, complete)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmmd2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKxyxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mhh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mKy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mKxy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mKxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mhsic_xx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mhsic_yy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 129.00 MiB is free. Process 760606 has 602.00 MiB memory in use. Including non-PyTorch memory, this process has 22.96 GiB memory in use. Of the allocated memory 8.79 GiB is allocated by PyTorch, and 115.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast \n",
    "scaler = GradScaler() \n",
    "\n",
    "# Repeat experiments K times (K = 10) and report average test power (rejection rate)\n",
    "for kk in tqdm(range(K), desc=\"Experiment\"):\n",
    "    torch.manual_seed(kk * 19 + n)\n",
    "    torch.cuda.manual_seed(kk * 19 + n)\n",
    "    # Initialize parameters\n",
    "    if is_cuda:\n",
    "        model_u = ModelLatentF(x_in, H, x_out).cuda()\n",
    "    else:\n",
    "        model_u = ModelLatentF(x_in, H, x_out)\n",
    "    epsilonOPT = torch.log(MatConvert(np.random.rand(1) * 10 ** (-10), device, dtype))\n",
    "    epsilonOPT.requires_grad = True\n",
    "    sigmaOPT = MatConvert(np.ones(1) * np.sqrt(2 * d), device, dtype)\n",
    "    sigmaOPT.requires_grad = True\n",
    "    sigma0OPT = MatConvert(np.ones(1) * np.sqrt(0.1), device, dtype)\n",
    "    sigma0OPT.requires_grad = True\n",
    "    # print(epsilonOPT.item())\n",
    "\n",
    "    # Setup optimizer for training deep kernel\n",
    "    optimizer_u = torch.optim.Adam(list(model_u.parameters()) + [epsilonOPT] + [sigmaOPT] + [sigma0OPT],\n",
    "                                   lr=learning_rate)\n",
    "    # Generate HDGM-D\n",
    "    for i in range(Num_clusters):\n",
    "        np.random.seed(seed=1102*kk + i + n)\n",
    "        s1[n * (i):n * (i + 1), :] = np.random.multivariate_normal(mu_mx[i], sigma_mx_1, n)\n",
    "    for i in range(Num_clusters):\n",
    "        np.random.seed(seed=819*kk + 1 + i + n)\n",
    "        s2[n * (i):n * (i + 1), :] = np.random.multivariate_normal(mu_mx[i], sigma_mx_2[i], n)\n",
    "        # REPLACE above line with\n",
    "        # s2[n * (i):n * (i + 1), :] = np.random.multivariate_normal(mu_mx[i], sigma_mx_1, n)\n",
    "        # for validating type-I error (s1 ans s2 are from the same distribution)\n",
    "    if kk==0:\n",
    "        s1_o = s1\n",
    "        s2_o = s2\n",
    "    S = np.concatenate((s1, s2), axis=0)\n",
    "    S = MatConvert(S, device, dtype)\n",
    "    N1 = Num_clusters*n\n",
    "    N2 = Num_clusters*n\n",
    "\n",
    "    # Train deep kernel to maximize test power\n",
    "    np.random.seed(seed=1102)\n",
    "    torch.manual_seed(1102)\n",
    "    torch.cuda.manual_seed(1102)\n",
    "    for t in range(N_epoch):\n",
    "        # Compute epsilon, sigma and sigma_0\n",
    "        ep = torch.exp(epsilonOPT) / (1 + torch.exp(epsilonOPT))\n",
    "        sigma = sigmaOPT ** 2\n",
    "        sigma0_u = sigma0OPT ** 2\n",
    "        \n",
    "        optimizer_u.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            # Compute output of the deep network\n",
    "            modelu_output = model_u(S)\n",
    "            # Compute J (STAT_u)\n",
    "            TEMP = MMDu(modelu_output, N1, S, sigma, sigma0_u, ep)\n",
    "            mmd_value_temp = -1 * (TEMP[0])\n",
    "            mmd_std_temp = torch.sqrt(TEMP[1]+10**(-5))\n",
    "            if mmd_std_temp.item() == 0:\n",
    "                print('error!!')\n",
    "            if np.isnan(mmd_std_temp.item()):\n",
    "                print('error!!')\n",
    "            STAT_u = torch.div(mmd_value_temp, mmd_std_temp)\n",
    "        J_star_u[t] = STAT_u.item()\n",
    "        scaler.scale(STAT_u).backward()\n",
    "        scaler.step(optimizer_u)\n",
    "        scaler.update()\n",
    "\n",
    "        # Print MMD, std of MMD and J\n",
    "        if t % 100 ==0:\n",
    "            print(\"mmd_value: \", -1 * mmd_value_temp.item(), \"mmd_std: \", mmd_std_temp.item(), \"Statistic: \",\n",
    "                  -1 * STAT_u.item())\n",
    "\n",
    "    h_u, threshold_u, mmd_value_u = TST_MMD_u(model_u(S), N_per, N1, S, sigma, sigma0_u, ep, alpha, device, dtype)\n",
    "    print(\"h:\", h_u, \"Threshold:\", threshold_u, \"MMD_value:\", mmd_value_u)\n",
    "    ep_OPT[kk] = ep.item()\n",
    "    s_OPT[kk] = sigma.item()\n",
    "    s0_OPT[kk] = sigma0_u.item()\n",
    "\n",
    "    # Compute test power of deep kernel based MMD\n",
    "    H_u = np.zeros(N)\n",
    "    T_u = np.zeros(N)\n",
    "    M_u = np.zeros(N)\n",
    "    np.random.seed(1102)\n",
    "    count_u = 0\n",
    "    for k in tqdm(range(N), desc=\"Testing\"):\n",
    "        # Generate Blob-D\n",
    "        for i in range(Num_clusters):\n",
    "            np.random.seed(seed=1102 * (k+2) + 2*kk + i + n)\n",
    "            s1[n * (i):n * (i + 1), :] = np.random.multivariate_normal(mu_mx[i], sigma_mx_1, n)\n",
    "        for i in range(Num_clusters):\n",
    "            np.random.seed(seed=819 * (k + 1) + 2*kk + i + n)\n",
    "            s2[n * (i):n * (i + 1), :] = np.random.multivariate_normal(mu_mx[i], sigma_mx_2[i], n)\n",
    "            # REPLACE above line with\n",
    "            # s2[n * (i):n * (i + 1), :] = np.random.multivariate_normal(mu_mx[i], sigma_mx_1, n)\n",
    "            # for validating type-I error (s1 ans s2 are from the same distribution)\n",
    "        S = np.concatenate((s1, s2), axis=0)\n",
    "        S = MatConvert(S, device, dtype)\n",
    "        # Run two sample test (deep kernel) on generated data\n",
    "        h_u, threshold_u, mmd_value_u = TST_MMD_u(model_u(S), N_per, N1, S, sigma, sigma0_u, ep, alpha, device, dtype)\n",
    "        # Gather results\n",
    "        count_u = count_u + h_u\n",
    "        print(\"MMD-DK:\", count_u, \"Threshold:\", threshold_u, \"MMD_value:\", mmd_value_u)\n",
    "        H_u[k] = h_u\n",
    "        T_u[k] = threshold_u\n",
    "        M_u[k] = mmd_value_u\n",
    "    # Print test power of MMD-D\n",
    "    print(\"Test Power of MMD-D: \", H_u.sum() / N_f)\n",
    "    Results[0, kk] = H_u.sum() / N_f\n",
    "    print(\"Test Power of MMD-D (K times): \", Results[0])\n",
    "    print(\"Average Test Power of MMD-D: \", Results[0].sum() / (kk + 1))\n",
    "np.save('./Results_HDGM_n'+str(n)+'_d'+str(d)+'_H1_MMD-D', Results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_mmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
