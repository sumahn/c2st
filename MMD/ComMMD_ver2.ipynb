{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils_HD import MatConvert, MMDu, TST_MMD_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(819)\n",
    "torch.manual_seed(819)\n",
    "torch.cuda.manual_seed(819)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "is_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Settings\n",
    "n_epochs = 1000\n",
    "batch_size = 100\n",
    "lr = 0.0002\n",
    "img_size = 64\n",
    "channels = 3\n",
    "n = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\")\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "N_per = 100 # permutation times\n",
    "alpha = 0.05 # test threshold\n",
    "N1 = n # number of samples in one set\n",
    "K = 10 # number of trails\n",
    "J = 1 # number of test locations\n",
    "N = 100 # number of test sets\n",
    "N_f = 100.0 # number of test sets (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming variables\n",
    "ep_OPT = np.zeros([K])\n",
    "s_OPT = np.zeros([K])\n",
    "s0_OPT = np.zeros([K])\n",
    "T_org_OPT = torch.zeros([K,J,3,64,64]) # Record test locations obtained by MMD-D\n",
    "COM_Results = np.zeros([1,K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deep network for MMD-D\n",
    "class Featurizer_COM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Featurizer_COM, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0)] #0.25\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(\n",
    "            nn.Linear(128 * ds_size ** 2, 300))\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        feature = self.adv_layer(out)\n",
    "\n",
    "        return feature\n",
    "\n",
    "# import torch.nn as nn\n",
    "# import torchvision.models as models\n",
    "\n",
    "# class Featurizer_COM(nn.Module):\n",
    "#     def __init__(self, pretrained=False):\n",
    "#         super(Featurizer_COM, self).__init__()\n",
    "        \n",
    "#         # Load pre-trained ResNet50\n",
    "#         self.model = models.resnet34(pretrained=pretrained)\n",
    "        \n",
    "#         # Replace the last fully connected layer\n",
    "#         # Number of features in the penultimate layer of the original ResNet\n",
    "#         num_ftrs = self.model.fc.in_features\n",
    "\n",
    "#         # Adjust the output features of the final fully connected layer\n",
    "#         self.model.fc = nn.Linear(num_ftrs, 300)\n",
    "\n",
    "#     def forward(self, img):\n",
    "#         feature = self.model(img)\n",
    "#         return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Configure data loader\n",
    "dataset_test = datasets.CIFAR10(root='/data4/oldrain123/C2ST/data/cifar_data/cifar10', download=True,train=False,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=10000,\n",
    "                                             shuffle=True, num_workers=1)\n",
    "# Obtain CIFAR10 images\n",
    "for i, (imgs, Labels) in enumerate(dataloader_test):\n",
    "    data_all = imgs\n",
    "    label_all = Labels\n",
    "Ind_all = np.arange(len(data_all))\n",
    "\n",
    "# Obtain CIFAR10.1 images\n",
    "data_new = np.load('/data4/oldrain123/C2ST/data/cifar10_1/cifar10.1_v4_data.npy')\n",
    "data_T = np.transpose(data_new, [0,3,1,2])\n",
    "ind_M = np.random.choice(len(data_T), len(data_T), replace=False)\n",
    "data_T = data_T[ind_M]\n",
    "TT = transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trans = transforms.ToPILImage()\n",
    "data_trans = torch.zeros([len(data_T),3,img_size,img_size])\n",
    "data_T_tensor = torch.from_numpy(data_T)\n",
    "for i in range(len(data_T)):\n",
    "    d0 = trans(data_T_tensor[i])\n",
    "    data_trans[i] = TT(d0)\n",
    "Ind_v4_all = np.arange(len(data_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3823efe494f74021a9ae2d28bdab62ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b54feea798040458dd132157026cbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1151622/70243074.py:57: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392035629/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
      "CUDA backend failed to initialize: Found cuPTI version 18, but JAX was built against version 20, which is newer. The copy of cuPTI that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================================\n",
      "epoch :  100\n",
      "our mmd:  0.15713149309158325 our mmd_std:  1.000084638595581 our statistic:  0.15711818635463715\n",
      "==============================================================================================================\n",
      "epoch :  100\n",
      "our mmd:  0.16343316435813904 our mmd_std:  1.000088095664978 our statistic:  0.16341876983642578\n",
      "==============================================================================================================\n",
      "epoch :  100\n",
      "our mmd:  0.18163546919822693 our mmd_std:  1.0001124143600464 our statistic:  0.18161505460739136\n",
      "==============================================================================================================\n",
      "epoch :  100\n",
      "our mmd:  0.18325933814048767 our mmd_std:  1.000121831893921 our statistic:  0.1832370162010193\n",
      "==============================================================================================================\n",
      "epoch :  100\n",
      "our mmd:  0.18367451429367065 our mmd_std:  1.0001147985458374 our statistic:  0.18365342915058136\n",
      "==============================================================================================================\n",
      "epoch :  100\n",
      "our mmd:  0.19486597180366516 our mmd_std:  1.000100016593933 our statistic:  0.1948464810848236\n",
      "==============================================================================================================\n",
      "epoch :  100\n",
      "our mmd:  0.17283868789672852 our mmd_std:  1.0000957250595093 our statistic:  0.17282214760780334\n",
      "==============================================================================================================\n",
      "epoch :  100\n",
      "our mmd:  0.17435090243816376 our mmd_std:  1.0000898838043213 our statistic:  0.17433522641658783\n",
      "==============================================================================================================\n",
      "epoch :  100\n",
      "our mmd:  0.16837871074676514 our mmd_std:  1.0000741481781006 our statistic:  0.1683662235736847\n",
      "==============================================================================================================\n",
      "epoch :  100\n",
      "our mmd:  0.16342374682426453 our mmd_std:  1.000088095664978 our statistic:  0.16340935230255127\n",
      "==============================================================================================================\n",
      "epoch :  200\n",
      "our mmd:  0.16390448808670044 our mmd_std:  1.0001014471054077 our statistic:  0.1638878583908081\n",
      "==============================================================================================================\n",
      "epoch :  200\n",
      "our mmd:  0.17948681116104126 our mmd_std:  1.000124216079712 our statistic:  0.17946451902389526\n",
      "==============================================================================================================\n",
      "epoch :  200\n",
      "our mmd:  0.17540700733661652 our mmd_std:  1.0000770092010498 our statistic:  0.1753934919834137\n",
      "==============================================================================================================\n",
      "epoch :  200\n",
      "our mmd:  0.16450875997543335 our mmd_std:  1.0000771284103394 our statistic:  0.16449607908725739\n",
      "==============================================================================================================\n",
      "epoch :  200\n",
      "our mmd:  0.1738893687725067 our mmd_std:  1.0000909566879272 our statistic:  0.17387355864048004\n",
      "==============================================================================================================\n",
      "epoch :  200\n",
      "our mmd:  0.1842515468597412 our mmd_std:  1.000091791152954 our statistic:  0.1842346340417862\n",
      "==============================================================================================================\n",
      "epoch :  200\n",
      "our mmd:  0.16851353645324707 our mmd_std:  1.0000821352005005 our statistic:  0.16849969327449799\n",
      "==============================================================================================================\n",
      "epoch :  200\n",
      "our mmd:  0.18624237179756165 our mmd_std:  1.0000966787338257 our statistic:  0.18622437119483948\n",
      "==============================================================================================================\n",
      "epoch :  200\n",
      "our mmd:  0.17607130110263824 our mmd_std:  1.0000910758972168 our statistic:  0.17605526745319366\n",
      "==============================================================================================================\n",
      "epoch :  200\n",
      "our mmd:  0.18047653138637543 our mmd_std:  1.0001014471054077 our statistic:  0.1804582178592682\n",
      "==============================================================================================================\n",
      "epoch :  300\n",
      "our mmd:  0.18363076448440552 our mmd_std:  1.0001089572906494 our statistic:  0.18361075222492218\n",
      "==============================================================================================================\n",
      "epoch :  300\n",
      "our mmd:  0.17941102385520935 our mmd_std:  1.000092625617981 our statistic:  0.1793944090604782\n",
      "==============================================================================================================\n",
      "epoch :  300\n",
      "our mmd:  0.16316552460193634 our mmd_std:  1.0000793933868408 our statistic:  0.1631525754928589\n",
      "==============================================================================================================\n",
      "epoch :  300\n",
      "our mmd:  0.18775106966495514 our mmd_std:  1.0001158714294434 our statistic:  0.18772931396961212\n",
      "==============================================================================================================\n",
      "epoch :  300\n",
      "our mmd:  0.18774504959583282 our mmd_std:  1.000105381011963 our statistic:  0.1877252608537674\n",
      "==============================================================================================================\n",
      "epoch :  300\n",
      "our mmd:  0.17434245347976685 our mmd_std:  1.0000749826431274 our statistic:  0.17432938516139984\n",
      "==============================================================================================================\n",
      "epoch :  300\n",
      "our mmd:  0.1650545597076416 our mmd_std:  1.000079870223999 our statistic:  0.16504137217998505\n",
      "==============================================================================================================\n",
      "epoch :  300\n",
      "our mmd:  0.17279618978500366 our mmd_std:  1.0000879764556885 our statistic:  0.17278099060058594\n",
      "==============================================================================================================\n",
      "epoch :  300\n",
      "our mmd:  0.19356614351272583 our mmd_std:  1.0001038312911987 our statistic:  0.19354604184627533\n",
      "==============================================================================================================\n",
      "epoch :  300\n",
      "our mmd:  0.19267401099205017 our mmd_std:  1.0001031160354614 our statistic:  0.19265414774417877\n",
      "==============================================================================================================\n",
      "epoch :  400\n",
      "our mmd:  0.17360219359397888 our mmd_std:  1.0000685453414917 our statistic:  0.173590287566185\n",
      "==============================================================================================================\n",
      "epoch :  400\n",
      "our mmd:  0.18290510773658752 our mmd_std:  1.000104308128357 our statistic:  0.1828860342502594\n",
      "==============================================================================================================\n",
      "epoch :  400\n",
      "our mmd:  0.1416800320148468 our mmd_std:  1.0000566244125366 our statistic:  0.1416720151901245\n",
      "==============================================================================================================\n",
      "epoch :  400\n",
      "our mmd:  0.17769035696983337 our mmd_std:  1.0000888109207153 our statistic:  0.1776745766401291\n",
      "==============================================================================================================\n",
      "epoch :  400\n",
      "our mmd:  0.15883108973503113 our mmd_std:  1.0000683069229126 our statistic:  0.158820241689682\n",
      "==============================================================================================================\n",
      "epoch :  400\n",
      "our mmd:  0.19257406890392303 our mmd_std:  1.0001168251037598 our statistic:  0.19255156815052032\n",
      "==============================================================================================================\n",
      "epoch :  400\n",
      "our mmd:  0.21025973558425903 our mmd_std:  1.0001075267791748 our statistic:  0.21023713052272797\n",
      "==============================================================================================================\n",
      "epoch :  400\n",
      "our mmd:  0.20765039324760437 our mmd_std:  1.0001155138015747 our statistic:  0.20762640237808228\n",
      "==============================================================================================================\n",
      "epoch :  400\n",
      "our mmd:  0.19819724559783936 our mmd_std:  1.0001254081726074 our statistic:  0.19817239046096802\n",
      "==============================================================================================================\n",
      "epoch :  400\n",
      "our mmd:  0.18004366755485535 our mmd_std:  1.0001083612442017 our statistic:  0.1800241619348526\n",
      "==============================================================================================================\n",
      "epoch :  500\n",
      "our mmd:  0.18226055800914764 our mmd_std:  1.0000836849212646 our statistic:  0.18224529922008514\n",
      "==============================================================================================================\n",
      "epoch :  500\n",
      "our mmd:  0.19776254892349243 our mmd_std:  1.000119686126709 our statistic:  0.1977388858795166\n",
      "==============================================================================================================\n",
      "epoch :  500\n",
      "our mmd:  0.19851696491241455 our mmd_std:  1.000103235244751 our statistic:  0.198496475815773\n",
      "==============================================================================================================\n",
      "epoch :  500\n",
      "our mmd:  0.1838749796152115 our mmd_std:  1.0000956058502197 our statistic:  0.18385739624500275\n",
      "==============================================================================================================\n",
      "epoch :  500\n",
      "our mmd:  0.16466504335403442 our mmd_std:  1.0000897645950317 our statistic:  0.16465026140213013\n",
      "==============================================================================================================\n",
      "epoch :  500\n",
      "our mmd:  0.17589034140110016 our mmd_std:  1.0000863075256348 our statistic:  0.17587515711784363\n",
      "==============================================================================================================\n",
      "epoch :  500\n",
      "our mmd:  0.18978141248226166 our mmd_std:  1.0001084804534912 our statistic:  0.18976081907749176\n",
      "==============================================================================================================\n",
      "epoch :  500\n",
      "our mmd:  0.1952684372663498 our mmd_std:  1.0000946521759033 our statistic:  0.19524995982646942\n",
      "==============================================================================================================\n",
      "epoch :  500\n",
      "our mmd:  0.18046240508556366 our mmd_std:  1.0001057386398315 our statistic:  0.18044331669807434\n",
      "==============================================================================================================\n",
      "epoch :  500\n",
      "our mmd:  0.17528411746025085 our mmd_std:  1.00009024143219 our statistic:  0.175268292427063\n"
     ]
    }
   ],
   "source": [
    "# Repeat experiments K times (K = 10) and report average test power (rejection rate)\n",
    "for kk in tqdm(range(K)):\n",
    "    torch.manual_seed(kk * 19 + N1)\n",
    "    torch.cuda.manual_seed(kk * 19 + N1)\n",
    "    np.random.seed(seed=1102 * (kk + 10) + N1)\n",
    "    \n",
    "    # Initialize deep networks for MMD-D (called featurizer)\n",
    "    featurizer_com = Featurizer_COM()\n",
    "    \n",
    "    # Initialize parameters\n",
    "    epsilonOPT = torch.log(MatConvert(np.random.rand(1) * 10 ** (-10), device, dtype))\n",
    "    epsilonOPT.requires_grad = True\n",
    "    sigmaOPT = MatConvert(np.ones(1) * np.sqrt(2 * 32 * 32), device, dtype)\n",
    "    sigmaOPT.requires_grad = True\n",
    "    sigma0OPT = MatConvert(np.ones(1) * np.sqrt(0.005), device, dtype)\n",
    "    sigma0OPT.requires_grad = True\n",
    "    if cuda:\n",
    "        featurizer_com.cuda()\n",
    "\n",
    "    # Collect CIFAR10 images\n",
    "    Ind_tr = np.random.choice(len(data_all), N1, replace=False)\n",
    "    Ind_te = np.delete(Ind_all, Ind_tr)\n",
    "    train_data = []\n",
    "    for i in Ind_tr:\n",
    "       train_data.append([data_all[i], label_all[i]])\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Collect CIFAR10.1 images\n",
    "    np.random.seed(seed=819 * (kk + 9) + N1)\n",
    "    Ind_tr_v4 = np.random.choice(len(data_T), N1, replace=False)\n",
    "    Ind_te_v4 = np.delete(Ind_v4_all, Ind_tr_v4)\n",
    "    New_CIFAR_tr = data_trans[Ind_tr_v4]\n",
    "    New_CIFAR_te = data_trans[Ind_te_v4]\n",
    "\n",
    "    # Initialize optimizers\n",
    "    optimizer_COM = torch.optim.Adam(list(featurizer_com.parameters()) + [epsilonOPT] + [sigmaOPT] + [sigma0OPT], lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------------\n",
    "    #  Training deep networks for MMD-D (called featurizer)\n",
    "    # ----------------------------------------------------------------------------------------------------\n",
    "    np.random.seed(seed=1102)\n",
    "    torch.manual_seed(1102)\n",
    "    torch.cuda.manual_seed(1102)\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        for i, (imgs, _) in enumerate(dataloader):\n",
    "            if True:\n",
    "                ind = np.random.choice(N1, imgs.shape[0], replace=False)\n",
    "                Fake_imgs = New_CIFAR_tr[ind]\n",
    "                # Adversarial ground truths\n",
    "                valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "                fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "                # Configure input\n",
    "                real_imgs = Variable(imgs.type(Tensor))\n",
    "                Fake_imgs = Variable(Fake_imgs.type(Tensor))\n",
    "                X = torch.cat([real_imgs, Fake_imgs], 0)\n",
    "                Y = torch.cat([valid, fake], 0).squeeze().long()\n",
    "\n",
    "                # ------------------------------\n",
    "                #  Train deep network for MMD-D\n",
    "                # ------------------------------\n",
    "                # Initialize optimizer\n",
    "                optimizer_COM.zero_grad()\n",
    "                # Compute output of deep network\n",
    "                com_modelu_output = featurizer_com(X)\n",
    "                # Compute epsilon, sigma and sigma_0\n",
    "                ep = torch.exp(epsilonOPT) / (1 + torch.exp(epsilonOPT))\n",
    "                sigma = sigmaOPT ** 2\n",
    "                sigma0_u = sigma0OPT ** 2\n",
    "                # Compute Compute J (STAT_u)\n",
    "                COM_TEMP = MMDu(com_modelu_output, imgs.shape[0], X.view(X.shape[0],-1), sigma, sigma0_u, ep, complete=True)\n",
    "                com_mmd = - COM_TEMP[0]\n",
    "                # com_hsic_xx = - torch.from_numpy(np.array(COM_TEMP[3])).to(torch.float32)\n",
    "                # com_hsic_yy = - torch.from_numpy(np.array(COM_TEMP[4])).to(torch.float32)\n",
    "                # com_hsic_xy = - torch.from_numpy(np.array(COM_TEMP[5])).to(torch.float32)\n",
    "                # com_mmd_std_tmp = np.maximum(COM_TEMP[1], 10**(-10))\n",
    "                com_mmd_std_tmp = COM_TEMP[1]                \n",
    "                com_mmd_std_tmp_np = np.array(com_mmd_std_tmp) \n",
    "                com_mmd_std_tmp_tensor = torch.from_numpy(com_mmd_std_tmp_np).to(torch.float32)\n",
    "                com_mmd_std = torch.sqrt(com_mmd_std_tmp_tensor + 1.0)\n",
    "                # com_mmd_std = torch.sqrt(com_mmd_std_tmp_tensor)\n",
    "                # com_mmd_std = com_mmd_std_tmp_tensor\n",
    "                # com_mmd_std = torch.tensor(1.0)\n",
    "                # com_mmd_std = com_mmd_std_tmp_tensor\n",
    "                COM_STAT_u = torch.div(com_mmd, com_mmd_std)\n",
    "                # COM_STAT_u = - torch.log(com_mmd) + torch.log(com_mmd_std)\n",
    "                # if COM_TEMP[1] < 0:\n",
    "                #     COM_STAT_u = - torch.abs(COM_STAT_u)                \n",
    "                \n",
    "                if (epoch+1) % 100 == 0:\n",
    "                    print(\"=\" * 110)\n",
    "                    print(\"epoch : \",epoch+1)\n",
    "                    print(\"our mmd: \", -1 * com_mmd.item(), \"our mmd_std: \", com_mmd_std.item(), \"our statistic: \",\n",
    "                    -1 * COM_STAT_u.item())\n",
    "                    # -1 * torch.div(com_mmd, com_mmd_std/10).item(), \"xx_hsic: \", -com_hsic_xx, \"yy_hsic: \", -com_hsic_yy)\n",
    "                    # -1 * torch.div(com_mmd, com_mmd_std/10).item(), \"hsic: \", -com_hsic_xy)\n",
    "                    \n",
    "                # Compute gradient\n",
    "                COM_STAT_u.backward()\n",
    "                \n",
    "                # Update weights using gradient descent\n",
    "                optimizer_COM.step()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # Run two-sample test on the training set\n",
    "    # Fetch training data\n",
    "    s1 = data_all[Ind_tr]\n",
    "    s2 = data_trans[Ind_tr_v4]\n",
    "    S = torch.cat([s1.cpu(), s2.cpu()], 0).cuda()\n",
    "    Sv = S.view(2 * N1, -1)\n",
    "    # Run two-sample test (MMD-D) on the training set\n",
    "    # dk_h_u, dk_threshold_u, dk_mmd_value_u = TST_MMD_u(featurizer(S), N_per, N1, Sv, sigma, sigma0_u, ep, alpha, device, dtype, complete=False)\n",
    "    # com_h_u, com_threshold_u, com_mmd_value_u = TST_MMD_u(featurizer(S), N_per, N1, Sv, sigma, sigma0_u, ep, alpha, device, dtype, complete=True)\n",
    "\n",
    "    # Record best epsilon, sigma and sigma_0\n",
    "    ep_OPT[kk] = ep.item()\n",
    "    s_OPT[kk] = sigma.item()\n",
    "    s0_OPT[kk] = sigma0_u.item()\n",
    "\n",
    "    # Compute test power of MMD-D and baselines\n",
    "    DK_H_u = np.zeros(N)\n",
    "    COM_H_u = np.zeros(N)\n",
    "\n",
    "    np.random.seed(1102)\n",
    "    dk_count_u = 0\n",
    "    com_count_u = 0\n",
    "\n",
    "    for k in tqdm(range(N)):\n",
    "        # Fetch test data\n",
    "        np.random.seed(seed=1102 * (k + 1) + N1)\n",
    "        data_all_te = data_all[Ind_te]\n",
    "        N_te = len(data_trans)-N1\n",
    "        Ind_N_te = np.random.choice(len(Ind_te), N_te, replace=False)\n",
    "        s1 = data_all_te[Ind_N_te]\n",
    "        s2 = data_trans[Ind_te_v4]\n",
    "        S = torch.cat([s1.cpu(), s2.cpu()], 0).cuda()\n",
    "        Sv = S.view(2 * N_te, -1)\n",
    "        # MMD-D\n",
    "        com_h_u, com_threshold_u, com_mmd_value_u = TST_MMD_u(featurizer_com(S), N_per, N_te, Sv, sigma, sigma0_u, ep, alpha, device, dtype, complete=True)\n",
    "\n",
    "        # Gather results\n",
    "        com_count_u = com_count_u + com_h_u\n",
    "        print(\"\\r\",\"Ours:\", com_count_u, \"MMD: \", com_mmd_value_u, end=\"\")\n",
    "        COM_H_u[k] = com_h_u\n",
    "\n",
    "    # Print test power of MMD-D and baselines\n",
    "    print(\"Our Reject rate_u: \", COM_H_u.sum() / N_f)\n",
    "    COM_Results[0, kk] = COM_H_u.sum() / N_f\n",
    "    print(f\"Test Power of Ours ({K} times): \")\n",
    "    print(f\"{COM_Results}\")\n",
    "    print(f\"Average Test Power of Ours ({K} times): \")\n",
    "    print(\"Ours: \", (COM_Results.sum(1) / (kk + 1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epoch 20 / lr: 0.0005\n",
    "[[0.23 0.94 0.25 0.37 0.6  0.1  0.36 0.31 0.23 0.4 ]\n",
    " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
    "Average Test Power of Baselines (10 times): \n",
    "MMD-D:  0.379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
